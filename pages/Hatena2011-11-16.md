---
title: "Hatena2011-11-16"
---

hatena

```
<body>
*1321431043*カルマン利得行列の意味
昨日の社内機械学習勉強会のハイライト、PRML P.357のカルマン利得行列(eq. 13.92)
[tex: K_n = P_{n-1}C^T(CP_{n-1}C^T + \Sigma)^{-1}]
の意味について忘れないうちにまとめておく。

Σが0に近い時、つまり出力確率の分散が小さい場合を考えてみよう。出力確率の分散が小さいってのは「センサーが優秀で、ほとんどノイズが乗らない」って状況ね。その場合

[tex: K_n \simeq P_{n-1}C^T(CP_{n-1}C^T)^{-1} = P_{n-1}C^T{(C^T)}^{-1}{(P_{n-1})}^{-1}C^{-1} = C^{-1}]

[tex: \mu_n = A\mu_{n-1} + K_n (x_n - CA\mu_{n-1}) \simeq A\mu_{n-1} + C^{-1} (x_n - CA\mu_{n-1}) = C^{-1} x_n]

[tex: V_n = (I - K_nC) P_{n-1} \simeq 0]

Znの(Xnが観測される前の)事前分布がeq.13.87だったことを考えると、これは「前回の推測値にAを掛けて推測してたけど、それはもう捨てちゃって観測されたデータからC^-1を掛けて戻した値を信じようよ！そっちのほうが信頼できるよ！」ということ。

一方Σがとても大きい時、つまり出力確率がノイズまみれの時はどうか？出力確率がノイズまみれっていうのは、要するに「真の値Znを観測しようとしたんだけどセンサーがヘボすぎて得られたXnがノイズだらけ」って状態ね。その場合

[tex: K_n = P_{n-1}C^T(VERYLARGE)^{-1} \simeq P_{n-1}C^T0 = 0]

[tex: \mu_n = A\mu_{n-1} + K_n (x_n - CA\mu_{n-1}) \simeq A\mu_{n-1}]

[tex: V_n = (I - K_nC) P_{n-1} \simeq P_{n-1}]

つまり「観測値がノイズだらけでぜんぜん信用ならない！こんなもの気にするのはやめて前回の推測値にAを掛けたものが今の値だと推測しよう！」ってこと。

今回の「前回の予測値なんか捨てて観測値を信じよう」と「観測値なんか捨てて前回の予測値を信じよう」は両極端であって、実用上は適度にブレンドした予測戦略が正しい。そのブレンドの割合をどうすればいいか？それを遷移確率や出力確率のパラメータから計算して教えてくれるのがカルマン利得行列なんだな。
</body>
```


[はてなダイアリー 2011-11-16](https://nishiohirokazu.hatenadiary.org/archive/2011/11/16)