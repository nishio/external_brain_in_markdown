
[[VAE]]
Variational Autoencoder (VAE)
Kingma & Welling (ICLR 2014) “Stochastic Gradient VB and the Variational Auto-Encoder”

[変分ベイズ法からVAEへ 持橋大地](http://chasen.org/~daiti-m/paper/vb-to-vae.pdf)
[[変分ベイズ]]の問題
- いい形の分布でないとEMアルゴリズムを導けない
- 因子分解の仮定 $q(z, \theta) = q(z)q(\theta)$が強い
普通の[[オートエンコーダ]]は隠れ変数zの分布が不明
そこでzが多変量標準正規分布であるモデルを考える
VAE=[[変分近似]]＋[[ニューラルネット]]

VAEって簡潔に言えばなんだろう
    - まずオートエンコーダがあって、それによって「潜在ベクトル」の概念が生まれて
    - もしこの潜在ベクトルの分布からサンプリングすることができるなら生成モデルに使える
    - しかし生のオートエンコーダでは実際の入力データと対応したベクトルの集合なので、そこからサンプリングしても学習に使ったデータしかでない
    - ここでこの潜在ベクトルの分布は「よりシンプルな分布(軸ごとのガウス分布？)の積である」という「変分近似」を使って、オートエンコーダ相当の構造を確率モデルにし、ベイズ更新していく形にするのが変分オートエンコーダ
- と言っていいのかな
- この記事だと「原論文ではオートエンコーダのベイズ化としてVAEを作ったわけではない」と指摘していて、僕がやったような流れの説明は適切じゃないということになる
    - [https://academ-aid.com/ml/vae](https://academ-aid.com/ml/vae)
- 指摘
    - VAE はベイズ推論ではない

[[ELBO]]
[[償却化推論]]
[[Jensenの不等式]]
[[ヘルムホルツマシン]]
変数変換トラック
- バスワイズ
重点サンプリング


