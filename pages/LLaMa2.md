
> [@goto_yuta_](https://twitter.com/goto_yuta_/status/1684732906005241856?s=20): 今更ながら、LLaMA2の論文が神大作で学習価値が高すぎる。
> [[RLHF]]に利用してるデータの中身とか、安全性を高めるためのRLHFの前後で出力がどう変化するとか書いてて、とにかくRLHFについて超詳しい。
> ![image](https://pbs.twimg.com/media/F2Fd7UraEAADBjS.png)![image](https://pbs.twimg.com/media/F2Fd7Upa8AAKM-8.jpg)

> [@goto_yuta_](https://twitter.com/goto_yuta_/status/1684454407734546432?s=20): Open LLM LeaderboardにあるLLaMA2のfine-tuningしたモデルのスコアが70.6で、GPT3.5の70に勝利した。
> オープンモデル史に残る快挙！