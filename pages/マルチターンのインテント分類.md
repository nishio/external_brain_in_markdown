---
title: "マルチターンのインテント分類"
---

Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification
[https://arxiv.org/abs/2411.14252](https://arxiv.org/abs/2411.14252)

<img src='https://scrapbox.io/api/pages/nishio/o1 Pro/icon' alt='o1 Pro.icon' height="19.5"/>
以下の論文は、大規模な多言語・ドメイン特化型のマルチターン対話データを自動生成し、それを用いてマルチターンの[[インテント分類]](以下MTIC)を高精度化する枠組みを提案している。概要は以下のとおり。

# 論文概要（ポイント）
1. ### 目的
    - オンラインECなど特定ドメインでの対話データは、インテント数が多く、言語も多言語にわたる場合が多い。十分なマルチターン対話データを人手で集めるのはコストが高いため、対話データを自動生成する新しい枠組みを提案。

2. ### 提案手法 (Chain-of-Intent)
    - まずHMM(Hidden Markov Model)を用いて「会話ターン数の分布」や「インテント遷移の確率」を学習し、ターン数とインテント列をサンプリングする。
        - その上で、大規模言語モデル(LLM)を使って各ターンの質問(ユーザ発話)と回答(チャットボット発話)を生成する。
    - HMMによる「インテント列のサンプリング」(Chain-of-Intent)と、LLMの自然な文生成を組み合わせることで、一貫性のあるマルチターン対話を得る。

3. ### データセット (MINT-E)
    - この生成手法で、EC領域の多言語マルチターン対話データ「MINT-E」を作成。
        - 8つの言語市場（例：インドネシア語、ベトナム語、英語など）・381種類のインテントを含む大規模なコーパスを公開。

4. ### MTICモデルへの応用 (MINT-CL)
    - 生成した対話データを用いて、「マルチターンのインテント分類(MTIC)」モデルを学習する。
        - 加えて「マルチタスク学習＋コントラスト学習(Multi-Task Contrastive Learning)」を導入し、回答の良し悪しをランキングするタスクを並行して学習させることで、表現をさらに洗練。
    - これによりインテント推定の精度を向上させる。

5. ### 実験と結果
    - GPT-4による生成対話の品質評価、および実際のチャットログを使ったインテント分類性能評価を実施。
        - 提案手法で生成したマルチターン対話を学習データに組み込むと、インテント分類精度が向上。英語圏を中心に大きく改善が見られる。低リソース言語でも改善はあるが、LLMの言語性能次第で質に差が出る課題も指摘している。

# 簡単な解説
- 主眼は「多数の意図([[インテント]])が存在し、かつ多ターンにわたる対話データ」を効率的に生成し、精度の高いインテント分類モデルを作る点にある。
- HMMで「インテント遷移」を明示的にモデル化してから、LLMにより自然で文脈的に一貫した問答を作る、という二段階方式が特徴。
- 生成した大規模データ(MINT-E)で学習するだけでなく、「回答の良し悪しを区別するコントラスト学習」を組み合わせる(MINT-CL)ことで、分類性能をさらに向上させている。
- 今後の課題としては、LLMの言語モデルが十分に訓練されていない言語（低リソース言語）に対して、いかに高品質な対話を生成するかが挙げられる。

private chat [https://chatgpt.com/c/679b38fa-ba68-8011-8415-69cf8843434a](https://chatgpt.com/c/679b38fa-ba68-8011-8415-69cf8843434a)
