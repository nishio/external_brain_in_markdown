---
title: "主観的興味深さ推定システム"
---

[[広聴AI]]のような「大量のオブジェクトがベクトル空間に埋め込まれている」的シチュエーションに関して

[[抽出された知見]]([[大量のオブジェクト]])の中から、分析者が興味深いと思うものを抽出したい
ただし、この「興味深さ」は主観であり、何を興味深いと思うかは既知ではない
- [[主観的興味深さ]]
- 分析者はそれを言語化できていない

なのでAIは分析者との対話を通じて「分析者が何を興味深いと思うか」を探らなければならない
- おそらく「すでに知っていることの一歩外側」
    - 関連: [[今持っている知識の一歩先の知識しか受け止められない]]

ランダム提示→-2~+2の五段階で「面白さ」を評価、そのデータを使って意見のembeddingの空間で[[ガウス過程回帰]]とかで未知のものに対する「面白い度」を推定、+1SDしてUCB-1的な[[利用と探索のトレードオフ]]をして提示していく

## ver.2
<img src='https://scrapbox.io/api/pages/nishio/GPT5/icon' alt='GPT5.icon' height="19.5"/>
目的
- 抽出された知見の中から、分析者本人が“興味深い”と感じるものを自動で選ぶ。ただし“[[興味深さ]]”は[[主観]]で、事前には分からない。
方法
1. まずランダムに知見を提示し、-2〜+2の5段階で“面白さ”を評価してもらう。
2. 各知見は埋め込みベクトルで表現する。評価済みの点をもとに、[[ガウス過程回帰]]（またはその近似）で、未評価の知見について**予想スコア（μ）と不確かさ（σ）**を推定する。
3. 次に提示する候補は UCB = μ + 1σ が高いもの（＝良さそう＆未知）を優先し、類似しすぎるものは減点して多様性も確保する。
4. これを繰り返すことで、その人の主観に合わせた“面白い知見”の提示精度が自動で向上する。

追記<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
- 一人で使っても面白いが、複数人で使うと「Aさんは面白がってるけどBさんは面白いと思ってないらしい、何が面白いのか説明して」みたいなことができる
    - [[Cartographer]]っぽい仕組み
    - 「みんなこれが面白いことに合意しています」もできる

<img src='https://scrapbox.io/api/pages/nishio/GPT5/icon' alt='GPT5.icon' height="19.5"/>
わかりやすく言い換えると、こういう仕組みです。

一言サマリ
人が“面白い”と感じる基準は最初は不明なので、少しずつ学習する。
ランダムに候補を見せて5段階で評価してもらい、似た意見は似たスコアになるという前提で“面白さ”を埋め込み空間上で予測。
その予測から、良さそう＆まだ不確かなものをバランスよく次に提示する。

なぜこうするの？
- “興味深さ”は主観で人それぞれ。ルールを先に決められない。
- だから対話的に学習していく必要がある（少量の評価→次の提示が賢くなる）。

仕組みのコア
1. 埋め込み（embedding）
    - 各意見をベクトル化し、「内容が近いほどベクトルも近い」地図を作る。
2. 評価データ（-2〜+2）
    - ランダムに数件を見せ、あなたの“面白さ”を点数で記録。
3. 予測（ガウス過程回帰など）
    - 評価した点を手がかりに、地図上のまだ見ていない点の
        - 予想の面白さ（平均） μ
        - 不確かさ（幅） σ
    - を推定する。
4. 提示の戦略（UCB）
    - 次に見せる候補は μ + 1σ（= UCB）が高いもの：
        - μが高い → たぶん面白い（活用）
        - σが大きい → まだ不確か（探索）
    - この和が大きいものを選べば、活用と探索のバランスが取れる。

実際の流れ（ステップ）
1. まずはランダムに20〜30件を提示し、-2〜+2で評価してもらう。
2. その評価を使って、埋め込み空間で面白さを予測（μ, σを計算）。
3. UCB = μ + 1σが高い順に次の5件を出す（似すぎを防ぐため[[多様性ペナルティ]]も加える）。
    - 元のメモにはない<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
        - [[Maximal Marginal Relevance]]したらいいとGPT5が提案している
4. 評価が増えるたびに予測を更新 → 提示がだんだん賢くなる。

直感的なたとえ
- 未踏の地図で美味しい店探しをする感じ。
- **評判（μ）**が高そうな店だけでなく、**情報が少ない（σが大きい）**穴場も少し混ぜる。
- そうすると見落としを減らしつつ、良店に早く辿り着ける。

用語ミニ辞典
- 埋め込み：文章の意味を数値ベクトルにしたもの。近い話題ほど近い点。
- ガウス過程回帰（GP）：近い点は似たスコアになりやすい、という滑らかさの仮定で**平均（μ）と不確かさ（σ）**を推定する方法。
- UCB（上限信頼境界, [[Upper Confidence Bound]]）：UCB = μ + 係数×σ。よさそう＆未知を両方重視して選ぶ指標。ここでは係数=1（=+1SD）。

すぐ使える評価ルール（現場メモ）
- スケール：-2（全然面白くない）〜 +2（とても面白い）
- 迷ったら0でOK（学習の邪魔にならない）
- 同じ項目がたまに再表示されるのは主観のブレ推定のため（品質向上）。

よくある疑問
- Q: なぜ“+1σ”なの？
- A: 係数が大きいほど“探索寄り”、小さいほど“活用寄り”。MVPでは1が扱いやすい。後で1.0〜2.0の範囲で調整すればよい。
- Q: GPじゃないとダメ？
- A: 近似（ランダム特徴×線形回帰）でも十分。まずは軽量版でOK。
    - これもGPT5が提案している<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
        - [[Random Kitchen Sinks]]
- Q: バラつきが大きい
- A: 評価を重ねる／重複評価でノイズ推定／“似すぎ抑制（多様性MMR）”を強める、で安定する。


