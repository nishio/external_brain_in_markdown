
2023-04-06
> [__gfx__](https://twitter.com/__gfx__/status/1643561940848091136) GPT-4にTypeScriptのことを聞くと極めて正確な答えが返ってくることが多くて驚くけど、これってたぶん世の中にTypeScriptの良質な文章がお多いからだよな。

> [__gfx__](https://twitter.com/__gfx__/status/1643565160328736768) ただし、最近の新機能については全然知らなくて取り付く島もない。だからGPT-4が書いてくるコードにsatisfiesが使われることもない。
>  このギャップはなかなか…分かってる人はいいけど、実用的にはしんどいかもしれないな。

> [omochimetaru](https://twitter.com/omochimetaru/status/1643572683320459267) 新しい高機能な言語を作るより、
>  古い言語をAI支援を受けながら使うほうが開発効率が良い、
>  って事になっちゃうと言語の進化にブレーキがかかりそうで嫌だなあと思ってます・・・

> [__gfx__](https://twitter.com/__gfx__/status/1643575579508355077) それでいうと、すでにbingみたいにリアルタイムで学習するエンジンも実現してるので、その懸念は杞憂だと思います。
>  それよりはむしろ「新しい言語がうまれてもサンプル数が少なくてAIがうまく書けず、広まらない」という懸念が大きいですね…。

> [omochimetaru](https://twitter.com/omochimetaru/status/1643576125011165185) なるほど。
>  AIが十分に賢ければ、テキストが公式の仕様書ぐらいしかなくても、そこから新しい概念を理解して使いこなすサポートをしてくれるといいのかな


> [nishio](https://twitter.com/nishio/status/1643812867773452290) 技術的にはもうできてるので近いうちに一般消費者にも「[[自分が興味がある分野の知識パッケージをLLMに与える機能]]」が降りてくる。そうなったら新しい言語の作者はLLM向けの知識パッケージを作って、その言語を使いたい人はそれをLLMに読み込ませて使うようになる。
- これを書いて、4/7に[[ChatGPT Plugins]]で実装して、11/7の[[OpenAI DevDay]]で[[Assistants API]]という名前で提供された(関連: [[Retrieval-augmented Language Model]])

> [nishio](https://twitter.com/nishio/status/1643813597792071680) 知識パッケージの作成って実は人間が読むためのドキュメントを作るよりも楽。というのは人間は短期記憶が限られてるので「良い順番」で知識を与えてやる必要があって、執筆者からするとこれがとてもしんどいのだけど、LLMに与える時には順番は関係ないから思いついたことをどんどん書けばいい
- [[執筆は一次元化]]

> [nishio](https://twitter.com/nishio/status/1643813862008033283) むしろユーザの質問をもとに「何が足りてない情報か」を特定してそれを追加していく作業をガンガン回す方が良いし、それをやるためのシステム作りが重要になる

2023-11-10
> [tokoroten](https://twitter.com/tokoroten/status/1722613867459870989) ChatGPTにPDFを食わせてカスタムモデルが作れるようになったので、
>  「書籍とはLLMに対する追加データセットである」というのは確定した未来になった感じがする
>
>  LLMと連携できる電子書籍サービスが次の覇権を取りそうだなぁ
>  本は積んでおくとLLMに食われて、そのうち役に立つ時代

> [unnonouno](https://twitter.com/unnonouno/status/1722628474937172341) 逆にいうと、執筆作業がLLMに食わせるデータづくりになりそう（もはや日本語である必要もなさそう）。出版じゃなくてカスタムLLM作成サービスになりそう

> [nishio](https://twitter.com/nishio/status/1722638049883082908) 書籍は人間が読みやすいように、情報が無理やり1次元化されているので、AIに対するインプット効率が効率が悪い
>  AIにとって都合が良いデータ構造で情報を作り出せるやつが強い、というのが次の時代に起きそうな気はしています
>
>  （西尾さんの4月くらいの会話ログから）[[人間のために書くよりLLMのために書く方が楽]]

> [nishio](https://twitter.com/nishio/status/1722775665345523735) あとで日付と関連リンクを書いておこうw

> [nishio](https://twitter.com/nishio/status/1722778725996175712) ちょうど昨日、FAQをLLMにつなぐ話をしてたんだけど、こういうFAQは書籍ではない「[[知識を伝達するフォーマット]]」で、検索がより良くなって質問に的確に答えれるようになるとより広い範囲で使われるようになるだろうね。
- [[Cybozu Days 2023-11-09]]

> [nishio](https://twitter.com/nishio/status/1722779478685110539) 書籍からFAQへの移行に関しては「はじめに何を知るべきですか？」「この本を読むことで何が得られますか？」などの質問をするボタンを置いておけば「最初の質問がわからないよー」という人にもいいし、一次元的に読みたい人向けには回答のたびに「次の質問候補」を一つ出してあげたらいい


> [tokoroten](https://twitter.com/tokoroten/status/1722783854761771161) FAQと言ってるものが、「本当にFAQのケース」と、「FAQによって線引きを行っているケース」が存在するので、前者はLLMに吸収されるけど、後者の機能があるので全部は取り込まれないと思う
>  [https://tokoroten.medium.com/情報ⅰ本-未収録原稿供養-その%EF%BC%92-c5c48fd04a69](https://tokoroten.medium.com/情報ⅰ本-未収録原稿供養-その%EF%BC%92-c5c48fd04a69)
>  ![image](https://pbs.twimg.com/media/F-iOovuaEAAyiqR?format=png&name=small#.png) ![image](https://pbs.twimg.com/media/F-iOs6SbMAAdGZ9?format=png&name=900x900#.png)

> [nishio](https://twitter.com/nishio/status/1722785628868530357) 後者に「公式情報」とか「コミュニティ」とかの出所ラベルが表示されてそれで受け手が判断するようになるんじゃない？

> [nishio](https://twitter.com/nishio/status/1722788318386204728) あと、RAGの「G」の部分で何を生成するかという話があって、「真実」を伝搬する「回答」を作ろうとする人が多いけどそれは筋悪だと思っている。「この記事が<ユーザの関心に基づいた要約>という点であなたの疑問を解決する役に立つのではないかと思いました〜」的な「意見」の生成の方がいい

