---
title: "説明のための説明"
---

> [hrjn](https://twitter.com/hrjn/status/1639269880590417921) 厳密にはそうでもないんだけどChatGPTによって価値がなくなる活動はAをBに変換するという部分なんだよね。
>
>  例えば、英語を日本語に翻訳する、アイデアをスライドに変換する、などなど。
>
>  一方でCをゼロから作る価値は残るのよね。つまり、実験したり観察したり作り出すことは今後も重要。
>  >golden_lucky: ChatGPT以降の世界、ぼくらがやってる「文脈を整理して原文を作る」という仕事に要求されることは、たぶん増えるんだよな。でも同時に（金銭的な）価値はおそらく（ますます）下がる。ドキュメントを代替するものとしてのAI、いまのChatGPTでは中途半端なので、はやく全部やれるようになってほしい


> [hrjn](https://twitter.com/hrjn/status/1639270904583663619) 問題なのは、世間の多くの知識労働者()は[[説明のための説明]]を多くさせられてて、なんなら説明できることが優秀さの証明とされてるのよね。雑にいうとアカウンタビリティーというやつ。
>
>  実はこの作業は無価値なんだけど、人間同士のコミュニケーションとしては重要だった。それがもしかすると破壊されるよね。


> [hrjn](https://twitter.com/hrjn/status/1639271545171329029) きちんと仕事さえしていれば毎日の作業ログや下手したらPCの操作ログから自動的に説明資料が生成される可能性はあるよね。
>
>  すると、週次の報告やら自己評価やらが全部AIで代替できる可能性ある。
>
>  これ画期的よね。

> [hrjn](https://twitter.com/hrjn/status/1639272222484250625) なんなら過去の類似プロジェクトから、妥当そうなマイルストーンの設定とか、タスクの細分化とかまでAIがアシストしてくれる可能性がある。
>
>  こういうのはある種コンサルが担ってきた仕事なんだけど原理的には大体可能だよね。

> [hrjn](https://twitter.com/hrjn/status/1639272627461058562) すると、どんどん物事の価値が新しいことを生み出すところに偏在化していく。そういうことなのだと思うなー。
