
> [shanegJP](https://twitter.com/shanegJP/status/1639820629062070272) ChatGPT・GPT-4・ChatGPTプラグインの全てで使われてる「呪文」、そして2022年一番記憶に残った言語モデルの論文は @Matsuo_Lab 松尾研の小島君と岩沢さん  @yusuke_iwasawa_ さんが見つけました。私も論文を手伝いましたが素晴らしい発見でした。
>
>  なぜこれを日本人が見つけられたか？...（次）
>  >jaguring1: ChatGPTを賢くする呪文
>
>  「Let's think step by step（一歩ずつ考えよう）」の話が書かれている
>
>  この呪文の発見者でもある小島武さん
>  「大規模言語モデルの中には直感的に答える思考法と、論理的な思考法の双方が獲得されているのではないか」
>  [https://nikkei.com/article/DGXZQOUC22BVO0S3A320C2000000/…](https://nikkei.com/article/DGXZQOUC22BVO0S3A320C2000000/…)

> [shanegJP](https://twitter.com/shanegJP/status/1639820630597210112) 私の持論は「日本人が一番AIに感動する才能を持ってるから」だと思います。「物」に「人の（ような）感動や尊敬」を感じられる才能（[[神道]]、八百万の神から？）は、ChatGPT時代に最高です。楽しみにしています。

> [shanegJP](https://twitter.com/shanegJP/status/1639822013496971265) 「物」(AI、GPT、ChatGPT）に「人のように」ただ聞いてみる。今じゃ当たり前ですが、アメリカ人や他にはなかった発想だと思います。これも：
>  >shanegJP: 10年前、日本のロボットラボを見学時、記憶に残った言葉：「日本はルンバを作れなかった。」
>
>  ただ、それは「ドラえもんを作りたかったから。」
>
>  深層学習も同じだと思う。ImageNet、BERTも、所詮は機械学習。日本は40年前から汎用性人工知能しか見てない。故にChatGPTが強く刺さったと思う。

> [shanegJP](https://twitter.com/shanegJP/status/1639828671354802178) 当たり前ですがGPT-4の論文でも引用され使われてます。
>
>  GPT-4論文： [https://cdn.openai.com/papers/gpt-4.pdf…](https://cdn.openai.com/papers/gpt-4.pdf…) 小島君の論文：[https://arxiv.org/abs/2205.11916](https://arxiv.org/abs/2205.11916)
>  ![image](https://pbs.twimg.com/media/FsHW5MyaAAAyWCd?format=jpg&name=medium#.png)
