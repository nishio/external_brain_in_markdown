---
title: "埋め込みベクトルにロジスティック回帰"
---

[[埋め込みベクトル]]に対して[[ロジスティック回帰]]
<img src='https://scrapbox.io/api/pages/nishio/GPT5/icon' alt='GPT5.icon' height="19.5"/>
- NLP：固定埋め込み＋ロジスティック回帰の評価・プロービング
    - SentEval（評価ツール）：文埋め込みを特徴量にしてロジスティック回帰 or MLPで下流分類を一括評価する定番。設定・CV手順が明示。
    - What you can cram…（Conneau+ 2018）：文法情報を測るプロービングタスクを提案。付録にロジスティック回帰結果も。
    - Probing Classifiers（Belinkov 2022 Survey）：プローブ（多くがロジスティック回帰）の長所・限界・改良を概観。 ([MIT Press Direct](https://direct.mit.edu/coli/article/48/1/207/107571/Probing-Classifiers-Promises-Shortcomings-and?utm_source=chatgpt.com))
    - Alt+ 2020（ACL）：TACRED等で埋め込み→ロジスティック回帰のプロービング設定を明記。 ([aclanthology.org](https://aclanthology.org/2020.acl-main.140.pdf?utm_source=chatgpt.com))
    - SBERT（Reimers & Gurevych 2019）：文埋め込みを作り、SentEvalのロジスティック回帰で転移性能を報告。 ([arXiv](https://arxiv.org/pdf/1908.10084?utm_source=chatgpt.com))

- 文書ベクトル：doc2vec系の古典と評価
    - doc2vec（Le & Mikolov 2014）：固定長ベクトルを作り、ロジスティック回帰等に渡す想定を明記した原典。 ([Computer Science](https://cs.stanford.edu/~quocle/paragraph_vector.pdf?utm_source=chatgpt.com))
    - Lau+ 2016（ACL）：doc2vecの実証評価。ロジスティック回帰を含む単純分類器で比較。 ([aclanthology.org](https://aclanthology.org/W16-1609.pdf?utm_source=chatgpt.com))

- 正規化特徴×ソフトマックス＝角度的ロジスティック（幾何学的理解）
    - ArcFace（CVPR 2019）：特徴＆重みを単位化したsoftmax（=ロジスティック回帰多クラス）に角度マージンを入れ、球面上の境界を解析。 ([CVFオープンアクセス](https://openaccess.thecvf.com/content_CVPR_2019/papers/Deng_ArcFace_Additive_Angular_Margin_Loss_for_Deep_Face_Recognition_CVPR_2019_paper.pdf?utm_source=chatgpt.com))
    - NormFace（2017）：L2正規化特徴とcos類似度ベースsoftmaxの学習上の論点を整理。 ([Department of Computer Science](https://www.cs.jhu.edu/~alanlab/Pubs17/wang2017normface.pdf?utm_source=chatgpt.com))

- 応用・実務系の補足例
    - Twitter Author Profiling（PAN’17）：単語埋め込み＋ロジスティック回帰で著者属性推定のベースライン。 ([ceur-ws.org](https://ceur-ws.org/Vol-1866/paper_81.pdf?utm_source=chatgpt.com))
    - （近年の実証）Embeddings×ペナルティ付きLRが強い：小型LMの埋め込み＋正則化ロジスティック回帰が17分類タスクで健闘という報告。 ([papers.ssrn.com](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5303840&utm_source=chatgpt.com))
