
[[日本語LLM]]に関する2つの問題を混同する人が多いから絵にしたよ
![image](https://gyazo.com/17f5a1e496eeeaac5100fbfc34b21785/thumb/1000)

1の視点で「日本語LLMに意味はない」的な話をする人がいる
2の視点
- [[GPT3では情報密度が逆転する]]
- [[日本語言語モデルについて考えたこと]]
    - > 今後どんどん成長していくであろう「言語をまたいで思考するAI」に対するパイプの太さが重要
    - > 「言語をまたいで思考するAI」は新たに発見された油田のようなもので、価値が湧き出してくる
    - > ここから湧き出してくる価値を、パイプの細い言語のユーザはあまり享受できない
- [[性能向上が頭打ちになるか、際限なく性能が向上するか]]
    - 頭打ちになるなら1の「規模の大きさによる差」が縮んでいく
- [[言語の力学]]
    - 現状、GPT4とは日本語でやり取りするより英語でやり取りした方が性能が良い
- [[日本語の言語モデルは必要か？]]
    - > 「別の小さいモデル」は無益だが「日本語に適したトークナイザー+αの層」は必要という話


一つの解決策はこういうの
- ![image](https://gyazo.com/4c9f57fda2d440f0c32a4d71c1b948d1/thumb/1000)
- これが有益であるかどうかは未知数
    - 「何もしないよりは挑戦した方が良い」的な発想

追記
- 頭打ちにならないなら？
- > [nishio](https://twitter.com/nishio/status/1639213542296674305) 「学習データの規模が大きい方が価値が高い」という前提するなら日本語で書かれた文章の総量は英語で書かれた文章の総量に及ばないし、話者の人数的にも差が縮まることはないのだから日本語の価値が相対的にどんどん下がっていくだけなのでは
    - 明治時代と同じように「英語を公用語にしないとヤバいのでは？」となる
        - [[英語公用語化論]]
