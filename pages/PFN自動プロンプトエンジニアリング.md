---
title: "PFN自動プロンプトエンジニアリング"
---

2023-10-13
[日本語LLMベンチマークと自動プロンプトエンジニアリング - Preferred Networks Research & Development](https://tech.preferred.jp/ja/blog/prompt-tuning/)
- [[PFN]] [[プロンプトエンジニアリング]] [[自動プロンプト]] [[自動プロンプトエンジニアリング]]
<img src='https://scrapbox.io/api/pages/nishio/claude/icon' alt='claude.icon' height="19.5"/>
この記事は、日本語大規模言語モデル(LLM)のベンチマークにおけるプロンプトエンジニアリングと、それを自動化する手法について解説しています。主なポイントは以下の通りです。
- LLMを実タスクに適用する際、プロンプトの違いが性能に大きな影響を与える。プロンプトエンジニアリングではプロンプトテンプレートの設計が重要。
- 日本語LLMベンチマークでもプロンプトテンプレートによって20ポイント以上の精度差が出る。LLMの真の性能を引き出すにはプロンプトの工夫が必要。
- プロンプト最適化のアルゴリズムを提案。遺伝的アルゴリズムを用いて、プロンプトテンプレートを交叉・突然変異させながら逐次的に改善していく。
- Stability AIの日本語LLMベンチマーク(JCommonSenseQA)で実験。プロンプト最適化により、各LLMで最大50ポイント程度の大幅な精度改善を達成。
- 最適化されたプロンプトテンプレートの特徴として、質問を後半に置く、選択肢の意図を明確に伝える、などがあった。LLM毎に最適なプロンプトの特性がある。
- プロンプトチューニングはLLMの性能向上に重要であり、自動化可能。一方、ベンチマークがプロンプトに敏感なため、LLM間の公平な比較にはプロンプトの影響を考慮する必要がある。
以上のように、プロンプトの自動最適化により、日本語LLMベンチマークの精度を大幅に改善できることが示されました。プロンプトエンジニアリングにおける自動化技術の重要性と、ベンチマークの評価におけるプロンプトの影響の大きさが明らかになった興味深い研究だと思います。
