---
title: "双シェマモデル"
---

- 双シェマモデルはモジュール型学習モデル
    - 環境が持つダイナミクスの変化を主観的に発見し新たなモジュールを作成していくモジュール型学習モデル

- シェマとは
    - ピアジェ
    - 認知発達における自己組織化的な過程
    - その基本的モジュールがシェマ
    - 同化と調節
        - 同化： シェマに外界からの情報を取り込む
            - どのシェマに取り込むか
        - 調節： 外界からの情報を取り込むためにシェマを変化させる
        - 同化・調節サイクルはk平均法の両ステップに似ている<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
    - 均衡化と分化
        - 上記、同化と調節のプロセスが均衡化
        - シェマとかけ離れたデータが入ってきたときに新しいシェマを作る、これが分化

- 双シェマ(Dual-schema)モデル
    - センサとモータを持っているロボットを想定
    - センサ入力は有限次元の実数値ベクトル
    - センサ入力を元に、内部処理系が意思決定し、行為出力を出す
    - 行為出力は数次元の実数値ベクトル
    - 時刻tにおける
        - センサ入力、知覚ベクトル: $S_t$
        - 行為出力、行為ベクトル: $A_t$
    - [[パースの記号論]]
        - 対象の概念とは「我々がそれに対していかに行為するか、また、その結果は何か」と考える
        - [[プラグマティズム]]の格率
        - つまり $U_t = (A_t, S_t, S_{t+1})$ が原始的な形
            - これを経験ベクトルと呼ぶ
        - さらに $F(S_t, S_{t+1}) = A_t$ を満たすようなFについて考える
            - 実空間で活動するエージェントにとって瞬間的なモータ出力が意味を持つことは少ない(2006)
            - 対象に働きかける一連の動作が行為であるという考えから方策関数 $a_t = \pi(s_t)$ こそが「行為」と呼ばれるべきもの(2006)
            - 後で説明するように意図を表現する関数と組み合わせることでこの2つの式が繋がる。

    - ビアジェのシェマを2つに分割
        - why<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
        - 行為シェマと知覚シェマ
        - 知覚シェマ: $\hat{F}=(F,\alpha): A_t = F(S_t, I_{t+1}) + \alpha\delta_t$
        - 行為シェマ:  $\hat{G}=(G, \beta): I_{t+1} = G(S_t) + \beta\delta_t$
        - ここで$I_{t+1}$ は時刻 t+1において主体が得たいと思う知覚(意図: Intention)で、理想的には$S_{t+1} \simeq I_{t+1}$
        - この2つの組み合わせで外界からの入力から行為を選択する
            - 行為のプログラムとはSからAを決める関数である $A_t = H(S_t)$
            - :$A_t = F(S_t, G(S_t))$
        - : $U_t$ が知覚シェマの関数Fを満たすかどうかが、そのシェマが外界に存在する対象を表象する記号として適切かどうか、に対応する。同化のプロセスがここで行える。
            - モデル誤差$(A_t - F(S_t, S_{t+1}))^2$ が小さければ、対象はFを持つ知覚シェマに属する
            - そこの誤差を取るんだ？ $(S_{t+1} - I_{t+1})^2$ではなくて？<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
    - 記憶容量に制限を加える
        - キュー
        - このキューにそのシェマ状態にあった時のU_tを格納していく
        - Fはそのキュー内のサンプルを最小誤差で近似できるように最適化する
            - 調節のプロセス
        - 記憶容量が限られていることが可塑性に貢献する
    - まとめ: 同化と調整
        - モデル誤差が最小になるシェマを選ぶことで、対象が属するシェマを特定出来る(同化)
        - そのシェマに対象を記録する。シェマの関数はその対象を表現できるように最適化する(調節)
    - 分化
        - 時刻tにおけるモデル誤差を時刻tにおける…
        - 信頼変数
        - Fの調節が十分でない場合Rの分母も同じ次元で大きくなる
        - Rの増加はシステム外部に何らかの変化が生じたことを認識できる

- 行為シェマを強化学習を通じて獲得
    - 双シェマベースの強化学習

階層的モジュール型学習機

- 感覚運動的な学習についての資源は
    - 主体と外界との相互作用の[[文脈]]、
    - 主体の[[身体性]]
    - 記憶についての[[資源的制約]]

- ピアジェのシェマを行為シェマと知覚シェマの2つに分割→双シェマ

- 双シェマとはピアジェのシェマ理論を元にした、自立ロボットが環境との相互作用を通して環境・対象のモデルに相当するシェマ（概念）を獲得する累積型モジュール学習器 (2005)


- 記号接地の考え方はロボット自身の主観的な世界を無視している、人間が持つ記号から始めるのではなく、ロボットにとっての記号が自身の記憶の組織化機構を通して生成されていく必要がある
- [[Umwelt]] = [[ある生物から見た主観的世界]] = [[環世界]]
    - J. Uexkull 生物記号論


- 記号の意味は客観的に存在するのではなく、認知発達的プロセスや、社会的なコミュニケーションを経て形成される

