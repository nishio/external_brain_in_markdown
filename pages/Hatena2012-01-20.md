
hatena

```
<body>
*1327030220*Pythonのpickle.dumpに3番目の引数がある話
cPickle.dump(obj, f, -1)みたいな使い方を見て、なんだこの-1？と思ったので調べてみた。簡潔に言えば、これはフォーマットの指定で、指定しなかったときは後方互換性のために初期のASCII形式での保存がおこなわれる。-1ってのは最新のを使えという意味で、今ならバージョン2ということになる。

>>
There are currently 3 different protocols which can be used for pickling.

-   Protocol version 0 is the original ASCII protocol and is backwards compatible with earlier versions of Python.
-   Protocol version 1 is the old binary format which is also compatible with earlier versions of Python.
-   Protocol version 2 was introduced in Python 2.3. It provides much more efficient pickling of new-style classes.
<<
http://docs.python.org/library/pickle.html

で、気になるのはファイルサイズとか速度とかだよね。

** 計測方法
Numpyのndarrayで1000x1000のサイズの0～1の乱数が入った行列を作り、それを文字列にシリアライズしてサイズと時間を計測した。サイズは文字列の長さ、時間はipythonの%timeitで適当な回数繰り返して計測した。

** 時間

まあざっくり100倍違いますね。

>||
%timeit s = cPickle.dumps(m)
1 loops, best of 3: 1.14 s per loop

%timeit s = cPickle.dumps(m, 1)
100 loops, best of 3: 18.4 ms per loop

%timeit s = cPickle.dumps(m, 2)
100 loops, best of 3: 18.4 ms per loop
||<

** サイズ

こちらの差は3倍弱。
>||
len(cPickle.dumps(m))
22217167

len(cPickle.dumps(m, 1))
8000141

len(cPickle.dumps(m, 2))
8000136
||<

** まとめ
version 1と2の違いは対象がndarrayだとよくわからないけど、少なくともversion 0を使い続ける明確な理由がないなら新しいバージョンを使った方がよさそう。

** おまけ
Cで書かれていないpickleの方を使った場合、version 0では速度に大した差が出ないが、1以降なら2～3倍遅い。
>||
%timeit s = pickle.dumps(m)
1 loops, best of 3: 1.16 s per loop

%timeit s = pickle.dumps(m, 1)
10 loops, best of 3: 42.3 ms per loop

%timeit s = pickle.dumps(m, 2)
10 loops, best of 3: 42.1 ms per loop
||<

*1327031473*gitにでかいバイナリファイルを入れるとどうなるか
ふと気になったのでgitにでかいバイナリファイルを入れたらどうなるのか調べてみた。

自分の発表が録画された112メガのaviファイルを実験対象に使う。

** cp
まずはgitを使わない普通のcpの時間を測っておく。
>||
real    0m0.744s
user    0m0.001s
sys     0m0.179s
||<

** git add
git addにはコピーの10倍以上の時間がかかる。
>||
real    0m9.339s
user    0m7.989s
sys     0m0.490s
||<

** git commit
git commitには意外と時間が掛からなかった。
>||
real    0m0.055s
user    0m0.002s
sys     0m0.031s
||<

** git clone
先ほど動画ファイルをcommitしたリポジトリをcloneしてみる。単純なファイルコピーに比べると3倍弱時間がかかる。

>||
real    0m1.943s
user    0m0.932s
sys     0m0.433s
||<

** git addには3パターンある

コミット済みのものを変更せずにそのままもう一度addした場合、きっとタイムスタンプを見てすぐに「変更されていない」と判断している。
>||
real    0m0.020s
user    0m0.001s
sys     0m0.004s
||<

タイムスタンプを変えるためにtouchしてからaddしてみた。それでも最初に追加した時ほどの時間は掛からない。何で判断しているのかな？
>||
real    0m0.616s
user    0m0.507s
sys     0m0.094s
||<

もちろんcatの追記でちょこっとファイル内容を変更してやると、初回add時と同じくらいの時間がかかる。
>||
real    0m9.159s
user    0m7.994s
sys     0m0.490s
||<

追記: time md5 ...ってしたらreal 0m0.617sだったので、2番目の例ではだいたいそれに類する処理が走っているんだと思われる。ということはむしろ3番目の例でこんなに時間がかかっているのが不思議なのか。バイナリーファイルかどうかとか無関係に差分を計算しているのかな？

さらに追記: 初回にaddしたときも同程度の時間がかかってるんだから差分計算じゃないよね、という指摘があったが全くそのとおり。んー、じゃあzlibでの圧縮に時間がかかっている？というわけで試しにtime zip ... ってやってみたら real 0m9.792s だった。なるほど、つまりは圧縮に時間がかかっている、と。

** まとめ
細かい数値は記憶に残らないのであえてバッサリ要約すると、1GBのファイルがコピーに7秒掛かる環境で、同じファイルがaddに80秒、cloneに20秒掛かる、という比率。addにかかっている時間は大部分がzlibで圧縮するのに掛かる時間。ネットワーク越しcloneなどは計測していない。ファイルサイズを変えての計測も試してない。

*1327044073*Pythonの例外を記録してみる
<a href='http://d.hatena.ne.jp/nishiohirokazu/20080403/1207194255'>よくあるエラー</a> が意外と参照されている。で、ふと「例外のフックを使って起こった例外を全部記録しておいて、たくさん溜まってから集計したら面白いんじゃないか」と思った。というわけでsite.pyに下のように書きたしてみた。

>|python|
def setup_exc_hook():
    "record exceptions"
    import sys, traceback
    def hook(type, value, tb):
        sys.__excepthook__(type, value, tb)
        lines = traceback.format_exception(type, value, tb)
        file("/Users/nishio/exclog.txt", "a").write(
            "".join(lines) + "\n" + "=" * 40 + "\n")

    sys.excepthook = hook

setup_exc_hook()
||<

とはいえ、どちらかというとPythonやプログラミングに不慣れな人のデータが欲しいわけなので…誰かそういう心当たりありませんか？あ、妻に使わせてみればいいのか？
</body>
```


[はてなダイアリー 2012-01-20](https://nishiohirokazu.hatenadiary.org/archive/2012/01/20)