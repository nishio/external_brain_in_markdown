---
title: "TRUTH, TRUST AND HOPE"
---

![image](https://gyazo.com/f37f5a18e9cc5231188d08458c6c33c6/thumb/1000)
[Deliberative Democracy Lab to Demonstrate Deliberative Polling® Method at the 2023 Nobel Prize Summit | FSI](https://cddrl.fsi.stanford.edu/news/deliberative-democracy-lab-demonstrate-deliberative-pollingr-method-2023-nobel-prize-summit)
> [@lessig](https://twitter.com/lessig/status/1657523023514091521?s=20): The 2023 Noble Prize Summit will have an extensive demonstration of the Deliberative Polling Method with AI-Assisted Stanford Online Platform at Nobel Prize Summit—You can participate!
- (ja) 2023 年のノーベル賞サミットでは、AI 支援のスタンフォード オンライン プラットフォームを使用した熟議投票法の広範なデモンストレーションが行われます。あなたも参加できます。
- [[Stanford Online Deliberation Platform]]

日程
- "25 May 12p-4p Eastern Time"
    - 全世界ユーザにアナウンスするのはもうちょっとわかりやすい表記にしてくれよー
- [Eastern Time](https://time.is/ET)
    - 3/12から夏時間が始まってUTC -4になってるらしい
- [https://www.timeanddate.com/time/zone/timezone/utc-4](https://www.timeanddate.com/time/zone/timezone/utc-4)
    - 午前1時開始だった😴
- あれ？今気づいたんだけどUTC-4の25日の12:00から始まるイベントって、JSTだと26日なのでは
    - ライフハック: [[時差のあるイベントの日程確認]]

[[Polis]]みたいなものかなと思ってたけど「事前にカメラとマイクのテストをしてね」というメールが来てるから音声コミュニケーションをするみたいだな

Small Group Session 1: 12:00-1:00
Plenary Panel: 1:00-1:40p
BREAK 20 MINS
Small Group Session 2: 2p-3p
Plenary Panel: 3p-3:40p
- Plenary: (pedagogy) Part of a lesson, usually at or towards the end, designed to review or evaluate the learning that has taken place.
- 要するにブレイクアウトルーム的なものが終わった後、みんな集まってセッションをやるよということか

事前試聴動画、自動文字起こしをGPT3に掛けたものを下に書いておく
[https://www.youtube.com/watch?v=PEnPu_Pby2k](https://www.youtube.com/watch?v=PEnPu_Pby2k)

- ソーシャルメディアは、私たちがお互いとやり取りする方法や情報を得る方法に影響を与えています。その広範な影響力から、一部の人々は、ソーシャルメディアプラットフォームがより規制されるべきかどうか、そしてその場合にはどのようなアプローチがあるべきかを考えるべきだと主張しています。一部の人々は、ソーシャルメディア企業の重要な規制を主張していますが、他の人々は自己規制できると主張しています。自己規制内には多くの可能なアプローチがありますが、このビデオではそれらをすべて網羅することはできませんので、このビデオでは、デマの文脈でのファクトチェックについて話しましょう。一緒にいくつかの政策提案を探ってみましょう。
- 最初の提案は、ファクトチェックのメカニズムは独立かつ統計的に代表的な市民監視機関によって審査されるべきだというものです。この提案は、ファクトチェックのメカニズムの合法性を向上させることを目指しています。なぜなら、現行のファクトチェックのメカニズムは、政治的スペクトルの一方に偏ったバイアスがあるとの指摘があるからです。現在、数多くのファクトチェック組織が存在していますが、市民の監視は存在していません。この独立した市民機関は、一般の市民を統計的に代表するものであり、つまり、誰もが監視機関のメンバーに選ばれる平等な機会を持つことを意味します。この提案の支持者は、既存のファクトチェック組織は一部の人々からバイアスを持っているとの見方があるため、人口統計学的に代表的な市民グループが監視を行うことで、ファクトチェックプロセスに正統性と信頼性を加えると主張しています。一方で、既に多くのファクトチェック組織が存在しており、市民による追加の監視はファクトチェックの結果を変えないため、この追加のメカニズムは不要であると主張する人もいます。一部の専門家は、人口の代表的な横断面がバイアスのない方法でファクトチェックのメカニズムを適切に評価することが困難である可能性があり、合意に達しない場合には信頼性が損なわれる可能性があると警告しています。
- 2つ目の提案は、プラットフォームが誤情報にさらされたユーザーに事後的に通知するべきだというものです。この提案は、ソーシャルメディアプラットフォームでの誤情報の拡散の有害な影響を減らすことを目指しています。つまり、あるコンテンツが投稿された後に誤りや誤導があると判明した場合、プラットフォームはそのコンテンツに関わったり閲覧したりしたユーザーに通知するべきです。
- この議論では、誤情報のラベリングは前の提案と同様に市民グループによって監督されているものとします。一部の人々は、この提案は比較的簡単に実施できると主張しています。なぜなら、多くのソーシャルメディア企業が既にファクトチェックのメカニズムを備えているからです。この政策は追加のステップとして、ファクトチェックを特定の投稿を見たり対話したりした人々にリンクさせ、彼らに通知するだけです。
- この政策提案は、デマの拡散に対抗するのに役立つ可能性がありますが、プライバシーや言論の自由に関する懸念も提起します。一部のユーザーは、プラットフォームが自分のコンテンツとのやり取りを追跡することに不快感を抱くかもしれません。また、一部の人々は、この政策が特定の考えを偽りや誤導とラベリングすることで言論の自由を抑圧する可能性があると主張するかもしれません。最後に、ユーザーはファクトチェックの通知を見たくないかもしれず、それが効果を失う可能性もあります。
- さて、議論を開きましょう。具体的な実施の詳細については時間的に十分な余裕がないかもしれませんが、私たちはファクトチェックのメカニズムがあるべきかどうかについて、皆さんの意見をお聞きしたいと思います。これらの提案に賛成するか反対するかに関わらず、皆さんの声を聞きたいのです。あなたの意見は重要です。
- ファクトチェックのメカニズムによって、デマや虚偽情報の拡散を防ぐことができる一方で、プライバシーや言論の自由といった懸念も生じます。また、市民が監視機関に参加することで、ファクトチェックのプロセスに正統性と信頼性を加えるという主張もありますが、実際には適切な評価や合意形成が困難な場合もあるかもしれません。
- どのようなメカニズムがあるべきかについて、あなたの考えを共有してください。ファクトチェックの仕組みについて、これらの提案に賛成する理由や反対する理由、または他のアイデアや提案があれば、ぜひお知らせください。あなたの声をお聞きすることは重要です。


[https://www.youtube.com/watch?v=l5Zi4asDbGk](https://www.youtube.com/watch?v=l5Zi4asDbGk)
[[prebunking]]

ソーシャルメディアは、私たちがお互いとやり取りする方法や情報を得る方法に影響を与えています。その広範な影響力から、一部の人々は、ソーシャルメディアプラットフォームについてより規制すべきかどうか、そしてその場合にはどのようなアプローチがあるべきかを考えるべきだと主張しています。一部の人々は、ソーシャルメディア企業の重要な規制を主張していますが、他の人々は自己規制できると主張しています。自己規制内には多くの可能なアプローチがありますが、このビデオではそれらをすべて網羅することはできませんので、このビデオではデジタルリテラシーについてのデマの文脈で話しましょう。

一緒に政策提案を探ってみましょう。提案は、プラットフォームがユーザーのフィードにプリバンキング教育コンテンツを含む教育的な告知を提供するべきだというものです。この提案は、ユーザーがデマを検出し、デマにさらされるリスクから免疫を得る能力を向上させることを目指しています。

ソーシャルメディアプラットフォームは主要なニュースの情報源となっており、一部の人々は、そのためにソーシャルメディアプラットフォームはユーザーが情報を評価する方法を知ることが重要であり、ユーザーに教育的なコンテンツを提供する責任があると主張しています。その方法の一つとして、公共広告（PSA）と呼ばれる告知を行い、その中にプリバンキング情報を含む教育的なコンテンツを掲載することがあります。ここでのプリバンキングとは、デマの制作に一般的に使用される戦術をユーザーに教えるメッセージのことを指します。例えば、感情を利用した操作的な言語、不明瞭さ、偽の二者択一、スケープゴート化、個人攻撃などです。

一部の研究は、プリバンキングが人々のフェイクニュースの見分ける能力を有意に向上させることを示しており、一般的なデマの戦術に対する感受性を低下させます。この第一提案の支持者は、教育的な告知がユーザーがソーシャルメディアプラットフォーム上で消費する膨大な情報を適切に評価するために必要な批判的思考能力を構築するのに役立つと主張しています。また、ユーザーがデマをよりよく検出することを学ぶことで、デマの流れを減らす助けとなるとも考えられています。

一方で、これらの教育的な告知はユーザーにとって侵害になる可能性があるという主張もあります。教育的なコンテンツはユーザーの行動を変える上で効果的ではないかもしれないという意見もあります。さらに、このような教育的な告知は、特定のタイプのコンテンツに対して偏見を持つまたは不公平なものと見なされる可能性があるという意見もあります。

さて、議論を開きましょう。実施の具体的な内容については時間的に十分な余裕がないかもしれませんが、デジタルリテラシーに関する要件があるべきかどうかについて、あなたの意見を共有してください。これらの提案に賛成する理由や反対する理由、または他のアイデアや提案があれば、ぜひお知らせください。あなたの声を聞きたいのです。


[https://www.youtube.com/watch?v=wtZu9u3V250](https://www.youtube.com/watch?v=wtZu9u3V250)
ソーシャルメディアは、私たちがお互いとやり取りする方法や情報を得る方法に影響を与えています。その広範な影響力から、一部の人々は、ソーシャルメディアプラットフォームがより規制されるべきかどうか、そしてその場合にはどのようなアプローチがあるべきかを考えるべきだと主張しています。一部の人々は、ソーシャルメディア企業の重要な規制を主張していますが、他の人々は自己規制できると主張しています。自己規制内には多くの可能なアプローチがありますが、このビデオではそれらをすべて網羅することはできませんので、このビデオではデマの文脈での研究と計測について話しましょう。

一緒にいくつかの政策提案を探ってみましょう。最初の提案は、プラットフォームが学術機関、ジャーナリスト、非営利団体、およびそれらの研究者がプライバシーに準拠した方法で簡単にデータにアクセスできるようにするべきだというものです。この提案は、プラットフォームが自身のアルゴリズムや製品の特徴の有害な影響について完全に認識していない可能性があり、認識していたとしても情報を透明に開示していない可能性があるという懸念に対応しています。研究者がデータにアクセスできるようにすることは、社会メディアの影響についての公衆の理解を高めるのに役立つと考えられています。これらの機関の研究者は、ソーシャルメディアプラットフォームの影響についての研究において重要な役割を果たしていると信じられています。残念ながら、研究者にはほとんどデータが提供されていません。EUのデジタルサービス法などの法律には、プラットフォームのデータを研究者と共有するための規定が含まれていますが、プライバシー法を尊重するようになっています。主要なソーシャルメディアプラットフォームは、自身のサービスに関与するデマに対する善意のある研究をサポートするという自発的な取り組みを行っていますが、これらの取り組みにも関わらず、研究コミュニティへのデータ提供は進んでいません。この第一提案の支持者は、プラットフォームが研究者が社会メディアの社会への影響について意味のある研究を行うことを可能にするため、研究者にデータへの簡単なアクセスを許可すべきだと主張しています。ソーシャルメディアプラットフォームの影響を独立して評価することができるようになるため、社会メディアプラットフォームの世界への影響を評価することができるようになります。一方で、どのような研究者が資格を持つのかを特定することや、悪意のある人物が研究者を装って科学的なユーザーデータを悪用することを防ぐことは困難であるとする意見もあります。ユーザーのプライベート情報を共有することによる潜在的なリスクとコストは利益を上回る可能性があります。安全なデータアクセスを実現するための技術の開発には、プラットフォームにとってかなりの財政的コストがかかるでしょう。さらに、機密性の高い企業情報の開示は競争上の優位性の喪失につながる可能性があり、ソーシャルメディアプラットフォームの利益に影響を与えるかもしれません。

2つ目の提案は、プラットフォームが研究者と協力して四半期ごとに会話の健全性指標を測定するべきだというものです。この提案は、特定のアルゴリズムや製品の特徴が会話の健全性にどのような影響を与えるかを理解することに関連しています。これらの効果を理解することで、良い特徴と悪い特徴を区別するのに役立ち、また、プラットフォームが良い特徴をより多く開発するように刺激することもできます。例えば、プラットフォームは極性指数を測定することができます。この指数は、特定の問題について2つ以上のグループ間の敵対心や対立の程度を測定します。また、プラットフォームは、コンテンツの多様性を測定することもできます。ユーザーが多様な視点に触れることができているかどうかを測定するものです。これらは会話の健全性を測定するための指標の例です。

プラットフォームは、ユーザーのエンゲージメントを測定するためにユーザーテストを行うことがよくあります。絵文字やニュースフィードの機能など、プラットフォーム上の新しい製品がユーザーにどの程度うまく受け入れられるかを測定するためです。会話の健全性の指標をこれらのユーザーテスト活動に組み込むこともできます。この第二提案の支持者は、会話の健全性を測定する指標を持つことは、プラットフォームが市民の建設的な対話を促進するためのアルゴリズムや他の仕組みを開発するインセンティブを生み出すと主張しています。これにより、プラットフォームはこれらの指標で良いスコアを獲得し、社会全体の良い結果につながるようになるでしょう。また、これらの指標はユーザーがどのプラットフォームを利用するかを選択する際にも役立ちます。

一方で、このような指標がユーザーにどのような影響を与えるかは明確ではありません。不適切な実施方法では、これらの指標がユーザーの会話の監視を容易にし、ユーザーに対する抑止効果をもたらす可能性があります。たとえば、独裁政権は抗議行動や反政府の組織化の試みを測定し、それに対処する可能性があります。また、これらの会話の指標は不完全であり、厳密に測定されない場合、誤った結論に導かれる可能性があります。また、望ましい指標のレベルが何であるかも明確ではありません。例えば、極端な対立が社会を分断する場合は悪いですが、抗議や改革を促進する場合は有用です。このような会話の指標は、悪意のある人物が簡単に入手できる可能性があります。AIの支援を受けることで、さらに容易になるかもしれません。

さて、議論を開きましょう。実施の具体的な内容については時間的に十分な余裕がないかもしれませんが、デマに関する研究と計測に関する規制があるべきかどうかについて、あなたの意見を共有してください。これらの提案に賛成する理由や反対する理由、または他のアイデアや提案があれば、ぜひお知らせください。あなたの声をお聞きすることは重要です。


[https://www.youtube.com/watch?v=5iO_8lmwpZw](https://www.youtube.com/watch?v=5iO_8lmwpZw)
ソーシャルメディアは、私たちがお互いとやり取りする方法や情報を得る方法に影響を与えています。その広範な影響力から、一部の人々は、ソーシャルメディアプラットフォームがより規制されるべきかどうか、そしてその場合にはどのようなアプローチがあるべきかを考えるべきだと主張しています。一部の人々は、ソーシャルメディア企業の重要な規制を主張していますが、他の人々は自己規制できると主張しています。自己規制内には多くの可能なアプローチがありますが、このビデオではそれらをすべて網羅することはできませんので、このビデオではデマの文脈でのアルゴリズムの規制について話しましょう。

一緒に政策提案を探ってみましょう。この提案は、プラットフォームが孤立した情報バブルを作り出している可能性があり、社会の分極化を増大させる可能性があるという懸念に対応しています。この提案は、プラットフォームが個人情報、関心、過去のユーザーの行動に基づいてコンテンツをターゲティングまたはフィルタリングする量を制限すべきだと主張しています。多くのソーシャルメディアプラットフォームは、ユーザーのフィードに表示されるコンテンツを優先するためにコンテンツ推薦アルゴリズムに頼っています。これらのアルゴリズムは、ユーザーの「いいね」や友達、場所などの個人情報を利用して、アルゴリズムを最適化し、ユーザーのエンゲージメントを最大化します。個人情報を使用することで、パーソナライズされたユーザーエクスペリエンスが生まれ、エンゲージメントが増加する一方で、一部の人々は、これが分極化を増加させていると主張しています。これは、優先化のアルゴリズムがコンテンツを過度にターゲットし、多様なコンテンツへの露出を減らす傾向があるためです。

この提案では、個人情報を利用しないコンテンツの一部を、ユーザーの情報が収集される前の初回ユーザーのように表示することになります。これは、コンテンツがランダムであるという意味ではありません。依然として、非パーソナライズされたコンテンツを提供するためのアルゴリズムが存在する可能性があります。この提案の支持者は、アルゴリズムが常に個人情報を使用しない場合、コンテンツの多様性と公平性を促進すると主張しています。プラットフォームはバイアスのあるコンテンツを表示する能力が低下し、その結果、ユーザーの信念を強化したり分極化させたりする可能性が減るでしょう。このアプローチは、多くの国のテレビ放送の規制と似ています。

一方で、この提案に反対する人々は、それがユーザーに表示されるコンテンツの関連性を低下させ、ユーザーエクスペリエンスを悪化させる可能性があると主張しています。それによりエンゲージメントや広告収益が減少する可能性があります。また、この提案は、対立する意見に曝されることが分極化や過激化を増加させる可能性があるとも主張されています。さらに、コンテンツ推薦アルゴリズムの規制は、スピーチの規制と見なされる可能性があるとも言われています。

さて、議論を開きましょう。実施の具体的な内容については時間的に十分な余裕がないかもしれませんが、アルゴリズムに関する規制があるべきかどうかについて、あなたの意見を共有してください。これらの提案に賛成する理由や反対する理由、または他のアイデアや提案があれば、ぜひお知らせください。あなたの声をお聞きすることは重要です。

[https://www.youtube.com/watch?v=UAEVcBm5b7A](https://www.youtube.com/watch?v=UAEVcBm5b7A)
ソーシャルメディアは、私たちがお互いとやり取りする方法や情報を得る方法に影響を与えています。その広範な影響力から、一部の人々は、ソーシャルメディアプラットフォームがより規制されるべきかどうか、そしてその場合にはどのようなアプローチがあるべきかを考えるべきだと主張しています。一部の人々は、ソーシャルメディア企業の重要な規制を主張していますが、他の人々は自己規制できると主張しています。自己規制内には多くの可能なアプローチがありますが、このビデオではそれらをすべて網羅することはできませんので、このビデオではデマの文脈での真正さについて話しましょう。

一緒に政策提案を探ってみましょう。第一の提案は、プラットフォームがユーザーを一意の匿名デジタル識別子に関連付けることが求められるべきだというものです。この提案は、ボットの悪影響を減らすために、メッセージが個別の個人から来るか、あるいは単なる複数の人物を演じるために作られたものかを適切に認識できるようにすることを目指しています。これにより、ボットのメッセージを適切にラベル付けしたり、フィルタリングしたりすることが可能になります。また、この提案では、ボットの操作者のアイデンティティも操作者のデジタル識別子と関連付けることが求められます。一部のプラットフォームでは実名を使用することを提案していますが、ユーザーは自分のアイデンティティを確認する必要はありません。この匿名性により、ユーザーは社会的な反応を恐れることなく自分の意見を表現することができ、オープンで自由な議論が生まれます。しかし、一方で、デジタル空間における匿名性は、責任のなさや透明性の欠如によって、ヘイトスピーチや嫌がらせ、暴力の扇動などの有害な結果をもたらす可能性もあります。さらに、この提案は、一部で増加していると主張されている悪意のあるボットの振る舞いに対処するためにも意図されています。この提案の支持者は、これによりアカウントと投稿を単一の人物に関連付けることができ、プラットフォームはボットを識別できるようになり、悪い行動を防ぎ、ソーシャルメディアプラットフォーム上の礼儀を向上させることができると主張しています。一方、ユーザーは自分のプライバシーを保持し、実際のアイデンティティはソーシャルメディア企業や他のオンラインユーザーから隠されたままになります。一方で、この提案は誤用や監視の可能性を引き起こし、異議を唱える声を抑圧する可能性もあると主張する人もいます。さらに、一意の匿名デジタル識別子はプライバシーやセキュリティ上の懸念を引き起こすこともあります。データの漏洩や流出によって、ユーザーの実際のアイデンティティがデジタル上で公開される可能性があります。また、ボットはデマや憎悪を含むコンテンツの拡散には限定的な役割しか果たさないため、多くの望ましくないコンテンツは既知のユーザーや確認済みのユーザーによって拡散されていると主張する人もいます。

第二の提案は、生成型AIを開発する企業は、そのプラットフォーム上で特定のコンテンツがAIによって生成されたものかどうかを検出できる技術を実装する必要があるというものです。この提案は、デマや憎悪的なコンテンツの作成に生成型AIが使用されることを減らすことを目指しています。生成型AIとは、テキスト、画像、音声、ビデオなどのコンテンツを人間が生成したコンテンツと見分けがつかないほどの美的な特徴を持つコンテンツを生成する人工知能モデルのことを指します。これらは、フェイクニュースの拡散、個人のなりすまし、詐欺行為など、悪意のある目的でのAI生成コンテンツの使用に関する懸念も引き起こしています。一部の人々は、この提案によりコンテンツの真正性を判断し、悪意のある目的での生成型AIの使用を制限することが可能になると主張しています。一方、AI生成コンテンツの検出はその真実性について何も言及していないと主張する人もいます。人間が生成したコンテンツも真実、虚偽、誤解を含むことがあるため、AI生成コンテンツの正確性を判断するためには追加の手段が必要です。また、現在の検出メカニズムは不正確であり、ほとんどのAI生成コンテンツを検出できず、一部の人間生成コンテンツをAI生成コンテンツと誤って分類することがあります。AIがより洗練されるにつれて、検出はより困難になるでしょう。

さて、議論を開きましょう。実施の具体的な内容については時間的に十分な余裕がないかもしれませんが、真正さに関する規制が必要かどうかについて、あなたの意見を共有してください。これらの提案に賛成する理由や反対する理由、または他のアイデアや提案があれば、ぜひお知らせください。あなたの声をお聞きすることは重要です。

日本語解説
> [AkioHoshi](https://twitter.com/AkioHoshi/status/1657996192020848641) デジタル民主主義に関心がある方は要チェック。
>  ノーベル賞サミット（5/24〜26、ワシントンDC）の場で、[[討論型世論調査]]（[[TRUTH, TRUST AND HOPE]]、DP）をデモ。「ネット上の誤報と分極化とそれに対する対策」をテーマに大規模なグループ審議の演習を実施する。

> [AkioHoshi](https://twitter.com/AkioHoshi/status/1657997005829050368) 討論型世論調査（DP）は、スタンフォード大のフィシュキン教授が1988年に提唱した熟議民主主義の手法。各国で実施事例がある。
>
>  日本では、2012年に原発をめぐる「エネルギー・環境の選択肢に関する討論型世論調査」を実施、結果は当時の民主党政権に伝えられた。
>  [わが国におけるこれまでの討論型世論調査 | KeioDP 慶應義塾大学DP研究センター](https://keiodp.sfc.keio.ac.jp/?page_id=327)

> [AkioHoshi](https://twitter.com/AkioHoshi/status/1657997393139499008) 近年では、このDPはAI支援のStanford Online Deliberation Platform（スタンフォードオンライン熟議プラットフォーム）によりオンライン対応。このツールは不正使用防止機能、リアルタイム分析機能を備える。
- [Online Deliberation Platform | Deliberative Democracy Lab](https://deliberation.stanford.edu/tools-and-resources/online-deliberation-platform)

> [AkioHoshi](https://twitter.com/AkioHoshi/status/1657997570030067719) [[Stanford Online Deliberation Platform]]（スタンフォードオンライン熟議プラットフォーム）の機能説明。
>  日本からも参加できる。
- [Online Deliberation Platform](https://stanforddeliberate.org/)
    - [[Better online conversations with automated moderation]]

> [AkioHoshi](https://twitter.com/AkioHoshi/status/1658039638731411456) オンライン熟議ツールStanford Online Deliberation Platformの論文に基づきツールの機能をいくつか紹介したい。
>  「[[モデレーションの自動化]]機能」が最大の特徴。（続
- [Deliberative Democracy with the Online Deliberation Platform (PDF)](https://www.humancomputation.com/2019/assets/papers/144.pdf)
- > Abstract
- >  We introduce the Stanford Online Deliberation Platform, a web-based platform that facilitates constructive discussions on civic issues with the use of an automated moderator. The automated moderator performs this function by stimulating participants to consider arguments from both sides of all proposals, maintaining civility in the discussion, encouraging equitable participation by all participants, and providing a structured collaboration phase for participants to come up with a small set of questions or action items. We will demo the functionality of this platform in the context of its primary intended application, that of online Deliberative Polling.
    - (DeepL) 我々は、自動モデレータを利用して市民的な問題についての建設的な議論を促進するウェブベースのプラットフォーム、スタンフォード・オンライン・デリベレーション・プラットフォームを紹介します。自動モデレーターは、参加者があらゆる提案の両側からの議論を検討するよう促し、議論の礼節を保ち、すべての参加者の公平な参加を促し、参加者が小さな質問セットやアクションアイテムを考え出すための構造的なコラボレーションフェーズを提供することによって、この機能を実行します。私たちは、このプラットフォームの機能を、その主な用途である「オンライン討論型投票」の文脈でデモを行います。

> [AkioHoshi](https://twitter.com/AkioHoshi/status/1658039886832889856) - 発言者は待ち行列で順番を待ち、制限時間内に発言
>  - 参加者はナッジによりアジェンダに従うよう奨励
>  - 発言を自動書き起こし。不快なコンテンツの検出や議題の会話が停滞しているように見える場合、Botは参加者からフィードバックを募り、ユーザーをブロック、あるいは議題を進めるかを決定する

> [AkioHoshi](https://twitter.com/AkioHoshi/status/1658040974877282304) - 今後は自動的な自然言語処理（NLP）によりアジェンダ管理、新規コンテンツの自動フラグ立て、主張の関連性スコアリングなどを追加予定。
>
>  感想：モデレーション自動化の可能性を追求している。関連性スコアリングは[[pol.is]]を連想します。
>  「熟議のモデレーションの自動化」は、今日的な取り組みだと思います。AIの使い方としても興味深い。
>  これがうまく機能するなら、大規模な討論型世論調査を可能にし、デジタル民主主義の可能性を大きく前進させることになると思います。


[[Deliberative]]
