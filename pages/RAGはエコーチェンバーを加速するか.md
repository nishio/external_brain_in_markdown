---
title: "RAGはエコーチェンバーを加速するか"
---

from [[Forkwell Library#55質疑]]

[[RAG]]は[[エコーチェンバー]]を加速するか
> [yappy0625](https://x.com/yappy0625/status/1798679401921671580) 都合のいい情報しか拾わなくなったりエコーチェンバーが加速したりしそうな気もするんだよなぁ。個人のためにカスタマイズしてるとも言えるかもだけど、忖度してくれる都合のいいAIに育ててるだけになっていないかどうか。
- LLMにRAGの形で「Xは悪である」みたいな[[価値判断]]を入れると、その価値判断が再現される確率は高くなる、多分そのことをさして「エコーチェンバーが加速」と表現しているのだと思う
- 一方で、今回の講演でメリットとして示した具体的な実例としては「生のLLMは自分が作ってるソフトウェアKozanebaのことを知らないからそれに関する議論もできないけど、RAGすればそれがどういう目的のソフトウェアなのか、どんな機能があるのかを知ってくれるので議論ができる」
    - これって「価値判断」ではなくて「[[知識共有]]」なんだよね
    - 知識のつながり、ネットワーク、を「自分が今やっているプロジェクト」のところまで延長すること
    - それによって自分のプロジェクトがより効率よく進むようになれば実益が生まれる
- エコーチェンバーのリスクを避けたいとしても、それの実現手段として「LLMにパーソナライズされた情報を入れない」を選ぶのはメリットとデメリットのバランスが取れていないように感じる
    - そのLLM以外の[[多様な情報源に触れる]]のがいいんじゃないかな
    - そもそもRAGするかどうかは簡単に切り替えられるので「読んでるLLM」にバイアスの懸念があるなら「読んでないLLM」に切り替えて使えばいいだけ
        - まあRAGしてないLLMですらバイアスはあると思うが。
            - LLMの判断が間違ってるのか「膨大な情報を読んで判断してるLLMに対して、ごく僅かな情報しか読んでないくせに自分の判断の方が優れてると思ってる自分」の判断が間違ってるのかは検証困難だと思うけどね
            - 試してみた: [[Qarasu-14Bに質問をする]]
                - RAG以前の問題なので、やはり「多様な情報源に触れる」しかないな
                - 自国内の人が自国言語で書いた文章だけを読むのはバイアスしてる
- 技術自体はニュートラルで、それを自分の価値判断を肯定させて確証バイアスを高める方向に使うこともできれば、「反論」や「違う視点」を出力させて議論を深めることに使うこともできる
    - 使い方は人間の手に委ねられてる
    - 「反論」を出力させるにしても、プロジェクトの知識をしっかり把握しているAIに反論されるのの方が、よくわかってなくて見当違いなことを言ったり、プロジェクトの個別の事情を把握せずに一般論を言ったりするAIよりも有用なので、やっぱりRAGで知識共有することは有用なのではないか
- ところで「エコーチェンバーを加速する」「忖度」という表現から、暗黙にそれらのことを「悪」であると価値判断してそうな雰囲気を感じた
    - エコーチェンバーが悪であると考えることは一面的な物の見方だと思う
    - [[フィルターバブルとプラグマティズム]]
