---
title: "クラスタリングとパーティショニング"
---

> K-Means has a few problems however. The first is that it isn’t a clustering algorithm, it is a partitioning algorithm. That is to say K-means doesn’t ‘find clusters’ it partitions your dataset into as many (assumed to be globular) chunks as you ask for by attempting to minimize intra-partition distances. --- [Comparing Python Clustering Algorithms — hdbscan 0.8.1 documentation](https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html)
K-Meansにはいくつかの問題があります。1つ目は、クラスタリングアルゴリズムではなく、パーティショニングアルゴリズムであるということです。つまり、K-meansは「クラスターを見つける」のではなく、パーティション内の距離を最小化しようとして、データセットを必要な数の(球状であると仮定される)チャンクに分割します。

<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>なるほど、これは一般的な言葉遣いとは言えないが、いい区別
- K-Means([[k平均法]])や[[Spectral Clustering]]は一般的に「[[クラスタリング]]」と呼ばれている
- しかし、これらの手法はクラスターを見つけるのではなくデータセットをチャンクに分割しているのだ、いわば「[[パーティショニング]]」だ、という主張
- [[DBSCAN]]の論文でも「そもそもクラスターって概念の定義が曖昧だ」と指摘しているね
    - [[DBSCANにおけるクラスタの定義]]
        - > クラスタ：すべての点が互いに密度連結であり、クラスタ内の任意の点から他の点へ到達可能である最大の集合。
