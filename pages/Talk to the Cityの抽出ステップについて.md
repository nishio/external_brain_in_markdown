---
title: "Talk to the Cityの抽出ステップについて"
---

![image](https://gyazo.com/9a06a82b7d3bdb2c7dc9542d6e09ad7b/thumb/1000)

[[Talk to the City]]の抽出ステップ(英語ではextraction step)について
- ここがLLM登場以前の分析手法と大きく違う興味深いところ
- いろいろな手段で得られた生データに対して、一旦LLMを使って0~n件の要素を抽出する
- どのような要素を抽出して欲しいのかを、プログラムではなく自然言語で記述できるようになったのがLLMでの進歩
    - 従来の手法では例えば「単語に分割して数を数える」などの方法になっていた
    - その"単語"は形態素解析エンジンの中で定義されていて手軽にコントロールできないものだった
- 数が多くて有用でないものが多いX(Twitter)などからのデータであれば、有用でない投稿からは要素が0件抽出され、実質的に「有用でないものを捨てる[[フィルタ]]」として機能する
- 複数の要素を含んでいる[[自由記述のアンケート]]に対して特に効果を発揮する
    - これは自由記述質問を[[多肢選択質問]]に変えるのに似た効果がある
    - プロンプトで強く制約すれば従来の多肢選択質問のようにこちらが決めた選択肢だけから選ばせることができる
    - が、多くの場合「事前に選択肢を決めなくて良い」という特徴が[[探索的な分析]]に有用である
        - アンケートを作る段階で多肢選択質問ではなく自由記述質問にしている場合、多くの場合は対象データの分布に対して知識が足りなくて事前に選択肢を設計できないことによるから
    - 自由記述の回答が集まった場合、ある程度の分量で人は全部読むことが辛いと思うようになる
        - 耐性は人それぞれで、100件で辛い人もいるし、数百件に耐えられる人もいるが、1000件は大体の人にとって辛い
        - 辛くなると人は構造を入れて圧縮しようとする
            - [[分類]]はその一つの形
            - ところが、この分類が思っているよりも難しい、それは「[[全体像を把握]]していない大量のデータ」に対して事前に適切な[[分類基準]]を決めることができないからである
            - 事前に多肢選択質問を作ることが難しいのと同じ
- TTTCはこのプロセスを支援する
    - TTTCが作り出す「分類」は、最初から満点ではないだろうが、人間がより良い分類基準を設計することの助けになる
