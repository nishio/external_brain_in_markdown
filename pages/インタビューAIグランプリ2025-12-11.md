---
title: "インタビューAIグランプリ2025-12-11"
---

from [[インタビューAIグランプリ]]

2025-12-11
<img src='https://scrapbox.io/api/pages/nishio/Claude/icon' alt='Claude.icon' height="19.5"/>
- orthogonalを分割: 「新論点（重要）」と「周辺情報」に分け、前者のみ抽出
- supportを削除: baselineの裏付けは「変更不要」の意味なので、レポートでは省略可
- 3分類に簡略化: challenge / refine / orthogonal のみ（supportは抽出しない）

<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
まず既存の専門家フィルターを参考に当事者検出とフィルターを作る。そのツールは単独で動作するようにして、船荷証券だけでなく「船荷証券電子化」および「人工知能基本計画」および「議員定数削減」のログを対象にする。この3つで問題なく動くことを確認する必要がある。これが最初のPhase

![image](https://gyazo.com/278f843f2b744ad528b066feb4bf2ab1/thumb/1000)

<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
PLANを確認して更新して。
PLANのPhase 2とPhase 3が逆だ。3分類で抽出するコードが先に必要だ。
抽出物を見て原文を確認したくなることがあるので、session idとmessage idをセットにして保管し、すぐに原文を確認できるようにすること

---
レポートが膨れ上がるのを防ぐために、前段階が幾つあろうと「各セクションごとに1件の最も優れた提案をとる」という仕組み
- この「最もすぐれた」の判定が人間と一致するかどうかは要確認だね

---
以前の船荷証券を用いた実験での抽出数と今回の実験での抽出数が異なっている理由は？

---
8%しか通過しないフィルタを「厳しすぎます」とCCは言うが、厳しすぎるかどうかは自明ではない

TODO
- 中間のやりとりを元に人間の評価のデータを作る

2025-12-13
## 1
僕のレポートの「通達でもよい」の話、ソースは
[https://depth-interview-ai.vercel.app/report/26bdda99-4824-454a-baf2-da2a4df228b0](https://depth-interview-ai.vercel.app/report/26bdda99-4824-454a-baf2-da2a4df228b0)
だということがわかりました。
ユーザが「さっさとやった方が良いから法令ではなく通達とかでも良いかもね」と発言したのは事実だが、実際に通達で機能するかどうかは不明ですね。
こういうのを抽出するか、しないかは、割と設計の根幹的なチョイスな気がします。
個人的にはこの人のチャットの中だと
「電子帳簿保存法のときは細かい要件ばっかりで現場が大変だったので、可能な限り要件を簡素にしてくれ。」
が、実体験を伴ったいい意見だな〜と思いました。
こういうのを抽出するか、しないかは、割と設計の根幹的なチョイスな気がします。
もう少し言語化が進んだ。
「問題解決のアイデアを集める」のか
「人々が経験したことを集める」のか
これは重要な設計判断であって、どっちつかずで進むとよくなさそうと思いました。

## [[素人のアイデアは口頭発表では独創性高く見えるが実現可能でない]]
「レゴマインドストームで独創的な進み方をするロボットを作れ」という課題でマインドストームを使ったことのない素人とロボコン優勝・準優勝者(以下、玄人)とで比較をした論文。
アイデアに関して写真と説明文でプレゼンテーションをして大学生たくさんが独創性を評価した結果、玄人と素人では独創性に差はなかった。
しかし、素人のほとんどはそのアイデアを実現できなかった。　#実現不可能
アイデアを実現できた素人のアイデアは、独創性が最低の評価だった。 #アイデアの実現
制約
玄人はアイデアを考える段階で、部品の数などの制約について注意を払っていた。
Finkeらの先行研究で「産出物の部品・カテゴリ・機能について制約を与えることは創造的な作品が作られる割合を高める」とされている。
玄人はこれを有効に活用していた。
プランの変更
失敗に基づくプラン変更の回数には有意な差がなかったが、失敗に基づかないプラン変更の回数は有意に玄人が多かった。
パーツ、メカニズム、アルゴリズムの各要因で失敗があった時に、同じ要因が修正された回数には有意な差がなかったが、異なる要因が修正された回数は有意に玄人が多かった。
私見：玄人は脳内に実行モデルを持っていることで、外から観察できない「脳内実験」を行っているのではないか。
「失敗に基づかないプラン変更」が具体的にどんなものだったのか知りたい。
この実験の観察者から見ると「うまく動いている、つまり失敗ではないのにプラン変更をした」と見えているものが、実際には「脳内モデルでの実行結果と、現実の実行結果に差がある」という現象であって、脳内の実行結果との差からプランを修正しているのでは。

## 2
素人のアイデアは口頭発表では独創性高く見えるが実現可能でない、なので制約条件を把握していない人からアイデアを募集してはいけない。一見独創的で素晴らしいアイデアが出てきて、有望なアイデアかと思って調べるとそれらは実現可能ではないことがわかってがっかりする。
熟議によってアイデアを生成するシステムを実装したい場合、今回のような「大勢の人がAIと1on1する」のではなく、専門家が「それは実現可能ではない」と即座にフィードバックできる環境で行うべきな気がする。このシステム自体は有用だと思う。人々がAIと話しながら or mini-publicしてアイデア出しをし、そのアイデアをAIが抽出して専門家に中継し、専門家の「こういう制約があるから無理」という意見をスピーディにフィードバックするような仕組み。
とりあえず今回はそういうシステムを作る話ではないのでパス。
では現状のシステムで何が集められるといいのか。それはLLMの学習データに入ってないような体験のデータだと思う。
たとえば「韓国からの輸入において船荷証券より先に荷物が届いてしまって困った」みたいな話は、
今回聞かれたから言語化された類のもので、通常状態でSNSやブログにたくさん書かれるような話ではないのでLLMの学習データに入ってない。
こういうものを見つけることができるといいのではないか。
いい言語化ができた。

2025-12-13
経験抽出はbaselineを必要としない
いまAI基本計画はbaselineがなかったため適当なものを使っているが
「baselineがないばあいにエピソードをグループ化する」というのをやってもいい


