---
title: "Tikhonov型のラプラシアン正則化"
---

[[Tikhonov]]型の[[ラプラシアン正則化]]

要点だけ、数式→直感→実装の順で。

何をしているか（定式化）
グラフ (G=(V,E))（ノード=コメント、重み (w_{ij})）上で、LLMの既存ラベル (Y_0\in\mathbb{R}^{n\times T})（one-hot/確率）を滑らかにしつつできるだけ保つ (Y) を求めます。目的関数は
[
\min_{Y}\ \underbrace{\mu|Y-Y_0|F^2}{\text{元ラベルへの忠実度}}
\ +
\underbrace{\mathrm{Tr}(Y^\top L Y)}_{\text{グラフ上の滑らかさ（Dirichletエネルギー）}}
]
ここで (L=D-W) は（正規化なしの）グラフ・ラプラシアン、(\mu>0) は重み。
勾配=0より
[
(\mu I + L),Y=\mu,Y_0
]
がTikhonov型ラプラシアン正則化の正規方程式。各列（クラス）ごとに独立に解けます（行はノード）。
効果：近いノードは似た (Y) を持ち、かつ (Y) は (Y_0) から大きく乖離しない → ラベルのノイズ除去＆境界の整形が高次元グラフ上で起きる。

直感（物理・確率の2つ）
- 物理比喩（ばね網）：各辺はばね、(\mathrm{Tr}(Y^\top L Y)=\sum_{(i,j)}w_{ij}|Y_i-Y_j|^2) はばねエネルギー。
ばねを緩めつつ、(\mu|Y-Y_0|^2) が外力として元ラベルに引き戻す。平衡点が解。
- 確率比喩（拡散/再スタート）：行確率 (S=D^{-1}W) を使えば
[
Y^*=(1-\alpha),(I-\alpha S)^{-1}Y_0,\quad \alpha=\tfrac{1}{1+\mu}
]
となり、**ランダムウォーク＋再スタート（RWR）**の定常解と等価。
つまり「近傍に確率が拡散するが、一定確率で元ラベルへ戻る」。

どのラプラシアンを使う？
- L（非正規化）：密度ムラに弱い場合あり。
- 正規化ラプラシアン：
    - (L_{\mathrm{rw}}=I-D^{-1}W)（推奨・実装楽）
    - (L_{\mathrm{sym}}=I-D^{-1/2}WD^{-1/2})（理論的にきれい）
(L_{\mathrm{rw}}) を使うと上のRWR等価式が素直に出ます。コサイン類似ならL2正規化→kNN→相互kNNで対称化が定番。

ハイパパラメータ
- (\mu)（または (\alpha=1/(1+\mu))）：
(\mu\uparrow) → (Y) は (Y_0) に忠実（拡散弱い）。
(\mu\downarrow) → 平滑化強く、境界をなめる。
まず (\mu\in[[0.02,0.2]]) を掃引し、**kNNラベル純度↑・精度↑**を指標に決める。
- k（近傍数）：30±を起点に。密度差が大きいなら相互kNN/可変近傍で安定化。

実装メモ
1. 重み行列：(w_{ij}=\max(\cos(x_i,x_j),0)^p)（(p\in[[1,3]])）で弱縁抑制。
2. 線形方程式：((\mu I+L)) は対称正定値 → 共役勾配法(PCG) + 前処理（IC(0)/AMG）が速い。
クラス数 (T) 列を同じ係数行列で解く（多右辺）。
3. 出力：各行 (Y_i) を確率解釈（正規化）し、`argmax` を最終ラベル、`max` を確信度。
4. 全件ラベルありなら (Y_0) は one-hot か確率。これは**“ラベル平滑化フィルタ”**として機能します。

他手法との関係
- Label Propagation（クランプ有）：一部ノードだけを厳密固定（(\mu\to0) かつ境界条件）。
- LGC：(Y_{t+1}=\alpha SY_t+(1-\alpha)Y_0) の収束解が上式に一致。
- GFHF：調和拡張（吸収境界）に相当。
→ 本手法はそれらを含む**統一的な“滑らかさ＋忠実度”**の枠組みです。

使い所（今回のケース）
- 全件LLMラベルがある → (Y_0) を丸ごと入れてノイズ除去。
- その後に**軽量分類器（ロジ回帰/SVM）**を高確信点で学習し直すと、決定境界がさらに安定。
- 可視化は supervised UMAP（`target=y_hat`, `alpha=confを不透明度`）で“見せ方だけ整える”。
必要なら、あなたの `W/L` の作り方に合わせてPCG実装の最小コードを書きます（SciPy/pyamg想定）。

[https://chatgpt.com/c/6900721d-dab8-8323-9b6e-cbc86dfa1cfc](https://chatgpt.com/c/6900721d-dab8-8323-9b6e-cbc86dfa1cfc)
