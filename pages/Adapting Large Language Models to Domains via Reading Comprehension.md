---
title: "Adapting Large Language Models to Domains via Reading Comprehension"
---

Adapting Large Language Models to Domains via Reading Comprehension
[https://arxiv.org/abs/2309.09530](https://arxiv.org/abs/2309.09530)

![image](https://gyazo.com/d8182e07b5d193f08b8a9d5854400327/thumb/1000)


<img src='https://scrapbox.io/api/pages/nishio/claude/icon' alt='claude.icon' height="19.5"/>この論文は、大規模言語モデル(LLM)をドメイン固有のタスクに適応させる新しい手法を提案しています。主な内容は以下の通りです:
1. ドメイン固有のコーパスで単純に事前学習を続けると、ドメイン知識は獲得できるがプロンプト能力が低下することを発見しました。
2. 生のコーパスを「読解テキスト」に変換する手法を提案しています。各テキストに関連するタスクを追加し、さらに一般的な指示も混ぜ込みます。
3. この手法を生物医学、金融、法律の3つのドメインで検証し、一貫した性能向上を確認しました。
4. 7Bパラメータのモデルで、50Bパラメータの専門モデルに匹敵する性能を達成しました。
5. ドメイン固有の読解テキストが一般的なベンチマークでも性能を向上させることを示しました。
6. この手法は計算効率が良く、様々な事前学習コーパスに適用可能です。
7. コードとデータは公開されています。
    - [[LMOps]]

要するに、ドメイン知識の獲得とプロンプト能力の維持を両立させる効率的な手法を提案し、その有効性を実証した研究だと言えます。


読解テキストとは、この論文で提案されている手法の核心部分です。具体的には以下のような特徴があります：

1. 変換プロセス：
        - 元のドメイン固有の生テキストを、一連の関連タスクを含む形式に変換します。

2. 構成：
        - - 元の生テキスト
        - - それに続く、テキストの内容に関連する複数のタスク

3. タスクの種類：
        - - 要約
        - - テキストから単語への変換
        - - 自然言語推論
        - - 常識推論
        - - 言い換え検出
        - - テキスト補完
        - など

4. 質問応答形式：
        - これらのタスクは質問応答の形式で設計されています。

5. 目的：
        - - モデルが生テキストからドメイン知識を学習できるようにする
        - - 同時に、多様なタスクを通じてプロンプトに対する応答能力を向上させる

6. 人間の学習プロセスの模倣：
        - 読んだ後に練習問題を解くことで学習効果が高まるという人間の学習過程にヒントを得ています。

7. 一般的な指示との混合：
        - さらに多様な入出力パターンを学習させるため、一般的な指示も混ぜ込みます。

この手法により、モデルはドメイン固有の知識を獲得しつつ、プロンプトへの応答能力も維持・向上させることができます。これは、単純にドメイン固有のコーパスで事前学習を続けるだけでは達成できない効果です。
