
[[word2vecによる自然言語処理]] p.64にこう書いた
> リンゴとトマトは似ています。どちらも赤いです。リンゴと青リンゴも似ています。どちらもリンゴです。ところが、青リンゴとトマトはあまり似ていません。

この現象は[[距離]]の要件である[[三角不等式]]を満たさない。

この問題の解決方法
- ベクトル間の距離・[[ベクトルの類似度]]をそのまま意味の類似度として扱うのではなく、いろいろな軸で潰した後での距離を類似度にする #軸を潰す
![image](https://gyazo.com/6f605fd9a0082f691b3b93c575ccd69e/thumb/1000)

- ベクトルをある軸方向に[[潰す]]ということは、その軸方向の違いを[[無視]]するということ
- [[次元削減は抽象化]] #抽象化 #特徴量の無視 #違いを無視
- 現状の [[word2vec]] によって作られるベクトルの 1 つの軸が「色の違い」のような都合の良い属性を表現しているかは疑問
    - word2vec はあくまで単語の周辺にどのような単語が出現するかの情報だけを基にベクトルを作っているから
- 人間の脳内では近いことが行われているのではないか
- [[Deep Learning]] で使われる技術のひとつに [[Dropout]] がある
    - ランダムに[[ニューロン]]を選び、その活動を止めて学習をさせる手法
    - これをやると[[汎化性能]]が上がる
    - ランダムに選んだニューロンの活動を止める
        - =そのニューロンが表現していた値を0にする
        - =ランダムに選んだ軸の方向に潰す

[[概念]]の[[類似度]]は[[距離]]ではない
[[単語の意味]]
[[意味の類似度]]

[[話が飛躍する人=ベクトル検索エンジンか？]]
- [[連想]]はベクトル検索か？違うと思う
    - ランダムに[[次元削減してから類似度検索]]してしてる