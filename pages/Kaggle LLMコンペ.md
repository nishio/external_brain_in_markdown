
> [tamaki_730](https://twitter.com/tamaki_730/status/1714060628720021510) [1st place. Single model inference | Kaggle](https://www.kaggle.com/code/ybabakhin/1st-place-single-model-inference/notebook) LLMコンペの1位解法すごい。1つのモデルで2種類のembeddingから得たcontextからそれぞれ推論して平均しただけで1位のスコアが出ている。

> [tamaki_730](https://twitter.com/tamaki_730/status/1714060736127725625) headだけ別に重み読み込んでいるけど学習時どういうふうにやるんだろ

> [yume_neko92](https://twitter.com/yume_neko92/status/1714976084796821752) 色々やってて少し時間かかったけどLLMコンペのソリューションを一通り読んだ。
>  ほぼ自分用の備忘録だけど、整理した内容を公開したので興味ある方いたらどうぞ。
>  [kaggle LLMコンペ　上位解法まとめ](https://zenn.dev/yume_neko/articles/7347ba6b081e93)

> [yume_neko92](https://twitter.com/yume_neko92/status/1714976866510193001) 読んでて思ったのは、やっぱりRetrievalが重要で、どれだけ質の良いwiki記事を集められるか、それを精度よく検索する工夫を上手くやってるチームが強かった。
>
>  その上で、より上位のチームはモデルもLLMモデルを上手く使ったり、タスクも上手いこと組み合わせたり改善してたり、色々工夫してた感じ。
