---
title: "pKozaneba2025-08-26~27"
---

[[Kozaneba]]をCanvas実装に変えることを想定した考察
- 基本的にほとんど作り直しだよね

紙での KJ法からKozanebaに変わってどう？
- KJ法ではなく[[こざね法]]だねこれ
- グループ化はしているが、まとめて動かしやすくするためだけに使われている
- KJ法的な「[[表札をつけて束ねる]]」をやってない
- UIが悪くて無意識に避けてる？
    - たたむと空間ができるけど、それって嬉しくない
- ズームアウトすると読みにくくなることを「[[なめらかな畳まれ]]」に使っている
    - 「[[大きな付箋]]」を使っている、ズームアウトしても読める付箋として。

今はテキストをインポートすると四角く並んでいる
- embeddingを使って2次元配置すべきか？
- 選択範囲メニューとして実装するか？

[[広聴AI]]はembeddingしてUMAPで二次元にしてから凝集クラスタリングしている
- 待てよ？最終的に付箋配置に落とすなら次元削減で2次元に落とす必要はないのかも？
    - というか実質的にグラフベースの次元削減とやってることがほぼ同じになりそう
- ここを0から作るのは一旦先伸ばしにしよう
    - 劣化UMAPを作ってしまう気がする

付箋座標を格子点にすることは、floatをbinに入れてる
- 1つのbinに入る数が大きくなりすぎないようにしたい
- スケールが大きすぎないようにしたい
- ここにパラメータのトレードオフがある
- 一旦可変のパラメータにして実験

かつて僕がKozanebaで実現した機能をGPT5は一発で出してくる...
- ![image](https://gyazo.com/a16ad53d74b30d8bc64c30bf50c7eb4a/thumb/1000)
    - 僕の実装は英単語でも容赦なく改行するからこっちの方が優れてるかも
    - しかもデモンストレーション用のこのサンプルデータ自体を作ってんだよな
    - 肌色変更絵文字とか超長い1単語とかのトラップに気づいてる
    - 句点の禁則処理は入ってないけど「やれ」っていうだけでできそう
    - このコード: [https://chatgpt.com/c/68ad5ac8-f398-8321-89c7-b4617c143f00](https://chatgpt.com/c/68ad5ac8-f398-8321-89c7-b4617c143f00)

1万枚付箋を出すテスト
- ![image](https://gyazo.com/1bc63da07fed10bc093dc751536f5ee3/thumb/1000)
- とりあえず1万枚出して性能上問題なくズームができることがわかった
- このコード: [https://chatgpt.com/c/68ad3ab0-defc-8332-a311-5c8191d70f0e](https://chatgpt.com/c/68ad3ab0-defc-8332-a311-5c8191d70f0e)

![image](https://gyazo.com/eea5ac10be052bd0fbb795b71c7e759e/thumb/1000)
- シンプルに付箋をUMAP位置に出すとこうなる

![image](https://gyazo.com/5e33f3001e82c38b3cf3a97cbb1d8bc4/thumb/1000)
- <img src='https://scrapbox.io/api/pages/nishio/Claude/icon' alt='Claude.icon' height="19.5"/>付箋の位置をNOTE_SIZE（120px）で割って整数格子点にスナップするように変更し、各格子点の付箋数をカウントしてトップ10を画面左下に表示するようにしました。
    - これはSCALE=600、90~60件重なっている
- SCALE=2000にしても50~26件くらい重なるな
    - ![image](https://gyazo.com/c635405f9f335311435e7277c04989cf/thumb/1000)
- SCALE=4000だとほとんど点、それでも35~15は重なる
    - ![image](https://gyazo.com/136c7d82efff052e552af2fd511739be/thumb/1000)

<img src='https://scrapbox.io/api/pages/nishio/Claude/icon' alt='Claude.icon' height="19.5"/>同一グリッドに複数の付箋がある場合に、螺旋状に近い空きグリッドを探して分散配置するロジックを実装しました。
- ![image](https://gyazo.com/3f1fc5ea8eceb5a41503265b877e2881/thumb/1000)

すごいぐりぐり動くようになった
- ![image](https://gyazo.com/7ee97058116f1417435d6bb1f3ca9e32/thumb/1000)
- ![image](https://gyazo.com/91ff7d8bc17257cecc6af4f72d1430eb/thumb/1000)
    - 初期画面

デプロイできた
[https://canvas-kozaneba-prototype.vercel.app/](https://canvas-kozaneba-prototype.vercel.app/)

四角い塊になっているところは基本的に座標を維持する散布図では一点に潰れてしまっているデータ
- 密度の高さを大きさに変換して可視化できている
- 散布図の点を半透明にすることで密度を可視化するのは以前にやった
    - 「[[内部構造がわかりやすい]]」というのが僕の肌感だったが、見た目がボケボケしてので見栄えが悪いので採用されなかった

「[[密度の高さを大きさに変換して可視化]]」について
- Q: [[Kernel density estimation]]と比べてどうなのか
- <img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
    - 散布図を描いた時に「1つ1つの点が意見です」を一般人は理解してないのでいちいち言う必要があり、それを説明なしで分からせようと言うのがそもそものきっかけ
        - 付箋を書いて並べるワークショップは経験したとこある人多いからね
        - なので「付箋が並んでいる図」を生成するところが主目的で、やってる過程で密度の高さが可視化できてるなという発見があったという話
    - Kernel Density Estimationして等高線で書くのはデータサイエンティスト向けにはいいんだけど、一般人の認知にとっては抽象度が散布図よりもさらに上がって理解しにくくなりそう
    - 試してみた
        - ![image](https://gyazo.com/a1bee73d3c565f2ebc1ebd92e5c56161/thumb/1000)![image](https://gyazo.com/02b2ad517a5dd746c5f4764165cd732f/thumb/1000)
        - 等高線ではなくヒートマップにした
        - 右はresolution=800, bandwidth=0.05
            - これくらい十分細かく描画するなら同様のクラスタ発見能力はありそう
        - <img src='https://scrapbox.io/api/pages/nishio/Claude/icon' alt='Claude.icon' height="19.5"/>
            - resolution=800
                - 密度を計算するグリッドの細かさを指定
                - 800×800の格子点で密度を計算
                - 値が大きいほど滑らかで高精細な画像が生成される
                - 計算時間は解像度の二乗に比例して増加
            - bandwidth=0.05
                - カーネル密度推定の「ぼかし具合」を制御
                - 0.05は非常に小さい値で、各データ点の影響範囲が狭い
                - 結果として局所的な密度集中が鋭く表現される
                - 小さすぎるとノイズっぽく、大きすぎると詳細が失われる
        - <img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/> 左はresolution=400, bandwidth=0.1
            - これだと粗い
        - 時間は左で18sec、右で45secという感じ (Apple M1 Pro)

[[p広聴AI]]
[[pKozaneba]]
[[Kozaneba]]

next [[pKozaneba2025-08-29]]
