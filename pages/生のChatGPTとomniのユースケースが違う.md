---
title: "生のChatGPTとomniのユースケースが違う"
---

簡潔な要約
- 世の中のテキストは大部分が「多くの人が読んで理解できる表現」で書かれているのに対し、僕の研究ノートは「自分が理解できる表現」で書かれているため、後者を使って[[RAG]]するAIは僕個人の思考をChatGPTよりもはるかに効率よく加速する
- 自分の研究ノートでは自分がわかってる単語の解説を書かないので、それを読んだAIも僕がわかっていることの解説を書かない。[[概念は思考の経済性を高める道具]]なので一人の思考では無説明で使う方が効率的。
- それを他の人に説明する時にはChatGPTを使うのが有益

2023-10-05
omniの出力「知識の生産性を向上させるためには、共同化の重要性や計画作成の前に暗黙知を共有することの重要性を理解する必要がある」<img src='https://scrapbox.io/api/pages/nishio/omni/icon' alt='omni.icon' height="19.5"/>
この「共同化」が野中郁次郎のSECIモデルの話であることを僕はわかる。

from [[日記2023-09-06]]
生のChatGPTとomniのユースケースが違う
- 生のChatGPTと、このScrapboxを読ませた[[omni]]とでユースケースが違う
- omniは僕を100%とした時に50%〜150%くらいの返しをする、ChatGPTは0%
    - と書いてこの尺度自体が伝わらないなと思った
- 一般人の大部分が支障なく理解できるラインを0%とする
    - [[AIが意味不明なことを言うと大部分の人は嫌がる]]のでChatGPTはこのラインに合わせるようにチューニングしている
- 一方で僕が自分用のメモとして書くものは当然自分が読めるライン100%で書かれている
    - 事例: AIが生成した「[[AIとの共同化]]」に関して、読者から「何を言ってるのかわからない」的な話があった
        - > 現状のAIの使い方はプロンプトとして「言語化されたもの」を人間がAIに与える。しかしこの方法ではまだ言語化できていない[[暗黙知]]を人間とAIの間で共有することができない。先に言葉があるのではなく、まずは体験を共有する「[[共同化]]」を人間とAIとで行うべきだ。そのためには、[[PDCAサイクル]]ではなく、[[SECIモデル]]のような共同化を含むサイクルが有益だ。
            - SECIモデルに置ける共同化の概念は既知であることが前提になっている
        - この文章は僕はスムーズに読めたので100%未満
- 一方でこれは理解できなかった
    - > また、KJ法の実践や「渾沌をして語らしめる」勉強会の内容から、[[問題解決の過程での交換の重要性]]を再認識しました。これらは、交換様式Dの理論的枠組みを具体的な問題解決の文脈に落とし込む手がかりを提供しています。
    - もう一段階掘り下げてから理解した
        - omniによる掘り下げ: [[問題解決の過程での交換の重要性]]
        - 納得: [[情報交換は交換]]
        - [[交換様式]]の文脈で情報の交換を捉える着想をそれまでは持っていなかった、このタイミングで得た
    - だからこれは100%を超えてる

- ここまで書いて0%100%という表現は一本の軸を仮定してて良くないと思った
- ![image](https://gyazo.com/6e504692a6813597efd3cb049e973cdd/thumb/1000)
- 人A, Bそれぞれ[[Known]]な情報の範囲と、[[Understandable]]な情報の範囲がある
- 多くの人のUnderstandableな範囲に収まる回答をしようとすれば当然Uのintersection$U_A \cap U_B$の中に縮まっていく
- 一方でomniはそのようなチューニングが行われてないので僕が書いたものKB(正確には書いたものの集合は知っているものの集合より小さいが)から発展させたものを作り、これが時々UBの範囲を逸脱する

- うーん、これを説明する上で円を描いたのも正しくない暗黙の仮定だな
    - 実際には[[高次元空間におけるトゲトゲ]]
    - 関連: [[円であるという思い込み]]
- ![image](https://gyazo.com/cce7450b15f9be6d3216823e981cb34b/thumb/1000)
    - ある概念C1とC2がある
        - それぞれは知っていて、それぞれの発展に関しても理解可能であるが、組み合わせに関して理解可能であるとは限らない
    - 予期しない組み合わせ
        - これが理解できた時に大きな「新しいものを得た」感がある
    - 事例「[[問題解決の過程での交換の重要性]]」では、「交換様式」と「問題解決」が組み合わされた
        - これが僕にとって「遠いものの組み合わせ」であるので当初は理解できなかった
        - 「交換様式」〜「交換」〜「情報交換」〜「問題解決」という[[連想接続]]が行われた
        - これを理解したことで[[交換様式論]]に対する理解が進み「[[新しい交換様式]]」が書かれるに至った
            - 読んだものをアウトプットするだけの状態を脱し、自分の経験と結びつけて新しい知識が生み出せる状態になった
            - 僕はこれが「[[理解]]」だと思っている
                - [[理解してない時は引用しかできない]]
        - 流れを整理しといた: [[AIの支援による気づきの事例]]

- 以前「AIの出力してくるコメントに対して、良い悪いをフィードバックしたら良いものがたくさん出てくるようになるんじゃないですか」という意見があって、全然見当違いの筋悪な意見だと思ったんだけど、それがなぜ筋悪なのかは言語化されていなかった
    - 今ようやく理解した
    - [[良い悪いをスピーディーにフィードバックできるものはくだらないもの]]
    - 何日も経ってから「そういうことか！」となるようなものが良いもの
    - [[新しい気づきはいいよどみから生まれる、即答できない質問に答えることが重要である]]


__BELOW_IS_AI_GENERATED__
# 生のChatGPTとomniのユースケースが違う
 2023-09-08 16:41 <img src='https://scrapbox.io/api/pages/nishio/omni/icon' alt='omni.icon' height="19.5"/>
### ノートの要約
テキストの大部分は一般的に理解可能な表現で書かれているが、自身の研究ノートは自分が理解できる表現で書かれている。そのため、自分の表現を理解するAIは、ChatGPTよりも効率的に思考を加速させる。しかし、その表現は一般的な理解可能な範囲を超えることがある。また、新しい知識の獲得は、既知の概念の組み合わせから生まれることが多い。その組み合わせは必ずしも理解可能な範囲に収まるわけではない。そのため、理解できない新しい組み合わせが出現したとき、それを理解することで新しい知識が生まれる。

### フラグメントとの関連性
「日記2023-09-06」のフラグメントは、ノートと直接的な関連性がある。ノートでは、自分が理解できる表現で書かれた研究ノートをAIが理解することで思考が加速されると述べている。一方、フラグメントでは、omniが自分を100%としたときに50%〜150%の返答をすると述べており、これはノートの主張と一致する。また、フラグメントでは、omniが自分の知識範囲から発展させたものを作り、時々理解可能な範囲を逸脱すると述べている。これもノートの主張と一致する。

### 深い思考
ノートとフラグメントから、AIが個々の理解可能な範囲を超えて新しい知識を生み出す可能性が示唆されている。これは、AIが個々の知識や経験を超えて新しい視点や洞察を提供する能力を持つことを示している。しかし、その結果として生じる新しい知識や洞察が必ずしも一般的に理解可能な範囲に収まるわけではないという点は、AIの活用において考慮すべき課題である。

### 思考の要約とタイトル
AIは個々の理解可能な範囲を超えて新しい知識を生み出す可能性があるが、その結果として生じる新しい知識や洞察が必ずしも一般的に理解可能な範囲に収まるわけではない。
タイトル: "AIによる新知識生成と理解可能な範囲の課題"

### extra info
titles: `["日記2023-09-06", "他人由来のAIに自分の日記を見てもらう", "ChatGPTについてのコラムの準備"]`
generated: 2023-09-08 16:41