
Q: [[機械学習]]を使うプログラムに対して、ソフトウェアテストはどうやって書くのか？
A:
- 「ソフトウェアテストをどうやって書くのか」が、動作が完全であることをどうやって保証するのか、という意味であるなら、機械学習ではそれはできない

- 一般のソフトウェアテストでは、入力されうる値の範囲・分布が事前に分かっている前提
    - その範囲内でおかしな出力を出すケースが存在しないことを確認するのがテスト
    - 境界線がどこにあるかは、仕様書などで事前に明確に言語化されている

![image](https://gyazo.com/de5f00b4e0b4aa027c25a60da4ce79c3/thumb/1000)


- 機械学習では境界が明確に言語化されていない
    - そもそも境界がぼやけているケースもある
    - 分布にオーバーラップがある図
    - ![image](https://gyazo.com/85afc26928233cf5ea56cb2cabfe18bb/thumb/1000)
    - オーバーラップがある時にどこに境界を引くか
    - 間違いの種類によって発生するコストが変われば、同じ分布であっても適切な境界が異なる
        - ビジネス要件の影響を受ける
    - AUCの話をするのも手だがROCの話からしないといけなくて手間

- この図では分布が観察できるかのように書いたが現実の問題には2つの難しさがある
    - この図では入力が1次元だが、一般にはもっと高次元で、人間が直接観察できない
    - この図では分布が既知だが、一般には分布は未知で、その分布から限られた個数のサンプリングによって得られたデータがあるのみ

- 次元
    - 人間が直感的に理解できるものより高次元
        - たとえば手書き文字認識を考えると、32x32のグレースケール画像という小さい画像でも1024次元ある
- 機械学習では、入力されうる値の分布が不明
    - 32x32のグレースケール画像をランダムに作った場合、それが手書き文字に見えることはほぼない
    - つまり実際の「32x32のグレースケールで書かれた手書き文字の分布」は1024次元の空間のごく狭い部分空間に分布しているはず。
    - その分布の形を人間はうまく記述できない。

- 学習データは不明な分布からのサンプリング結果
    - なので学習データに対して100%の精度を出すことは重要ではない
    - まだ手元にない、将来サンプリングされるデータに対して高い精度を持つことが必要
    - その精度は何によってはかることができるのか

- そこで入力データの一部を「これは未来に得られるデータだと見なそう」と考えて、分けて置く
    - 学習結果がその「分けておいたデータ」でどの程度の精度を持つのかを観察する
    - see [[データを分ける意味]]
