
hatena

```
<body>
*1321925412*混合ガウス分布モデルのクラスタをk平均法とEMアルゴリズムと変分ベイズでそれぞれ推定
「クラスタは球状だ」と想定しているk平均法が苦労するように、細長くて交差したクラスタのデータを使った。また変分ベイズの「クラスタの個数を自動調整する」というメリットを確認するために、クラスタの個数は2, 4, 8個で行った。EMアルゴリズムと変分ベイズでは、k平均法ができていない「長細いクラスタだ」という推定ができている。またEMアルゴリズムではクラスタの個数は人間が与えないといけないが変分ベイズでは自動調整されている。ただし、自動調整に失敗することも結構あるので「何回か実行して一番良かったものを取る」というアプローチが必要だろうな。変分ベイズの8クラスタでの実験は10回やって一番良かったものを取っている。4クラスタの実験は6回。それぞれ初期状態から20ステップの学習過程を動画にしている。

** k平均法
k平均法では細長いクラスタを見つけられないのでこれが限界
[f:id:nishiohirokazu:20111122102925g:image]
4クラスタの例。クラスタの個数を増やすと、本当は細長い1つの正規分布なのに複数のクラスタに刻んでしまう。
[f:id:nishiohirokazu:20111122102919g:image]
8クラスタの例。1つの正規分布が4つのクラスタに刻まれてしまっている。
[f:id:nishiohirokazu:20111122102908g:image]

** EMアルゴリズム
最初はk平均法みたいに間違った2本の腕をとってしまうが、その後細長いクラスタが交差していることに気付く。
[f:id:nishiohirokazu:20111122103116g:image]
4クラスタの例。ひとつの分布を3つのクラスタでわけあっている。
[f:id:nishiohirokazu:20111122103109g:image]
8クラスタの例。4本の腕を4つのクラスタが取って、残りの4クラスタはすることがなくて適当な外れ値の周りをうろついている。このまま学習を続けると外れ値に無理やりフィトしてその下の図みたいになる。
[f:id:nishiohirokazu:20111122103102g:image]
外れ値に無理やりフィットした例(ただし上のとはパラメータの違う実験)
[f:id:nishiohirokazu:20111122111058p:image]

** 変分ベイズ
これは細長いクラスタであることを見つけ損なっている。右のクラスタがずるずる広がり続けているのでもうしばらくするとEMの2クラスタの例みたいに細長いクラスタであることを発見するかも。
[f:id:nishiohirokazu:20111122105203g:image]
最初は4本の腕それぞれをクラスタがカバーするが、上の2つのクラスタが下のクラスタに追放されて2個に縮約する。
[f:id:nishiohirokazu:20111122105158g:image]
最初の1ステップで8つのクラスタで4本の腕を奪い合い、取れなかったクラスタが消えている。そのあとは上の4クラスタの例と同じ。
[f:id:nishiohirokazu:20111122105152g:image]

8クラスタで開始して、3クラスタまでしか縮約しなかった例。このあと下の1クラスタになる例と同じことが起きるかも。
[f:id:nishiohirokazu:20111122105147g:image]

8クラスタで開始して、縮約しすぎて1クラスタになってしまった例
[f:id:nishiohirokazu:20111122105141g:image]

** ライセンス
ここに載せた画像はCC-BY3.0ライセンスにするので作者の氏名を明示すれば自由に使って構いません。業務の時間を使って作ったので「サイボウズ・ラボの西尾泰和」とか書いてもらえるとうれしいです。
</body>
```


[はてなダイアリー 2011-11-22](https://nishiohirokazu.hatenadiary.org/archive/2011/11/22)