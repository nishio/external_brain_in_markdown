
色々な相談に乗った時にメモしておく場所

- シンプル
    - モデルはなるべく小さくしたい
        - モデルが大きいと実験時間がかかり、単位時間でできる実験の回数が減る
        - モデルが大きいとまともな学習結果になるために必要なデータ量が増える
    - 実務投入されてからの運用コスト
    - ブラックボックスが大きいと予期せぬものが出てくる不安

- ニューラルネットの中間層のサイズなど、各種のハイパーパラメータはどうやって決めるのか
    - 実験を繰り返して決める
    - 特にDeep Learningによる画像処理では、公開されているデータセットがあり、それに対して色々な手法を大勢の人が試し、どの程度の精度になったかの情報が蓄積されている。
        - たとえば [MNIST](http://yann.lecun.com/exdb/mnist/) ではニューラルネットでないKNNなども含めて精度の一覧が掲載されている。
    - 一方、実務ではデータセットは一般公開されていない(自分たちだけが持っている)ケースがほとんど
        - 状況設定に違いがある

- パブリケーションバイアス


- [[機械学習]]コンサルタントのメモ
