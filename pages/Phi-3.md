---
title: "Phi-3"
---

> [hillbig](https://twitter.com/hillbig/status/1782902418449326325) Phi-3 3B, 7BはLLMを使って学習データをフィルタリングしたり教科書のようなデータを生成し作られた高品質な学習データで学習（一般のデータで学習し推論能力獲得した後高品質なデータを知識を導入）。スマホで動かせ、10倍近く大きいGPT-3.5などのMMLUスコアなどに匹敵する。[https://arxiv.org/abs/2404.14219](https://arxiv.org/abs/2404.14219)
>
>  実際に試した感じでは少し外れたタスクでは性能が急激に劣化したり出力が壊れやすいように思う。Llama3 8Bなどではそういうことはなかった。モデルが小さいので学習データ設計時にかなり狙った（ベンチマーク等の）タスクに集中し、そこに記憶容量をわりあてているためと思われる。
>  とはいえ、同じ性能を達成するモデルサイズが毎年数分の一のペースで小さくなっているのは驚異的。予想されていたように、より強い生成モデルを持つところがデータ作成にも競争力を持ち、強いモデルを作るという循環がおきつつあるarxiv.org

