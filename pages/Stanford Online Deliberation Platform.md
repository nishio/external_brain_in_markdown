---
title: "Stanford Online Deliberation Platform"
---

Stanford Online Deliberation PlatformはDeliberation([[熟議]])のためのプラットフォーム
- [[ノーベル賞サミット2023]]で体験機会が提供されていたから参加した
- 公式サイト: [Online Deliberation Platform](https://stanforddeliberate.org/)

![image](https://gyazo.com/8457df5eef689040f782170be700e685/thumb/1000)

実際に体験して
- これは[[熟議支援システム]]だが、[[ブロードリスニング]]ではない
    - 8人程度で口頭での議論をするシステム
- 「熟議」という点では[[Polis]]より踏み込んでいるが、僕がPolisに感じている魅力とは軸が直交してる
- 公式サイトでは"Better online conversations with automated moderation"と表現している。この「[[自動モデレーション]]」を「AIモデレーション」と呼ぶのは2023/05時点では過大解釈だと思う


自動モデレーションはビデオ会議の司会をやる仕組み
- 続けて長く話し過ぎの人を切る
    - 発言時間は可視化される
- ある人が話してる時に次に話したい人はキューに入って全員に「次に話したい人がいる」が可視化される
    - ![image](https://gyazo.com/438fbeb9809bfadf4ceb11cec33653d1/thumb/1000)
- 議題ごとにあらかじめ設定と消費具合が可視化される
    - 予定時間過ぎると発言終了時に容赦なく次の議題に移る
    - 逆にみんな沈黙すると「次の議題に進む？」という投票が発生する
        - これのスクリーンショットは撮り損ねた、下記は似たダイアロ
        - ![image](https://gyazo.com/f6959bb4530c5688b09edd76233b8b90/thumb/1000)
    - 時間が過ぎると下記のように予定時間枠からはみ出して赤くなる
        - ![image](https://gyazo.com/35dbcc6c2e17f2c04bcc8c92afa9ec4f/thumb/1000)
- 割り込みボタンを押すとメインの話してる人と割り込んだ人の二人の顔がでる(スクリーンショット失敗)
    - 「Aさんの会話ターンにBさんが割り込んでる」という構図が明確になる
    - 割り込みで話せる時間にも上限があるかな？確認し損ねたが僕なら上限をつける
- しばらく黙ってると発言を促される
    - ![image](https://gyazo.com/d992f5d6fa8a6373536befea43692613/thumb/1000)
    - 促されたからといって発言し易くはならない(個人の感想です)


投票部分
- ![image](https://gyazo.com/bcb90ea3954d6f92f4c1f0938bf9fc18/thumb/1000)
- ステートメントを各個人がそれぞれ0〜1件書く
- それに対して議論順投票をする
    - この投票部分のアルゴリズムは[[ボルダルール]]かなと思う
    - ![image](https://gyazo.com/d32a01593165d9c5c5907ce88c1a8627/thumb/1000)
- それぞれの議論時間に議論し、提出者はそれを踏まえて文章をアップデートできる
    - ![image](https://gyazo.com/21ce697d3f1486a848631309f2de89a7/thumb/1000)
- その後で選好順投票をする
    - 2回やってそれぞれのトップを採用する
    - ![image](https://gyazo.com/cf1373c289f36123381e331103887c07/thumb/1000)
        - 採用されたw
        - 今回のイベント設計では、ここで選ばれた質問が、その後のパネルディスカッションの話題候補に使われる、という仕組みだった
            - これはケースバイケースだと思う

考察
- Polisとは似ていない。
    - 投票的なのは最後の「質問の優先順位を決める」のところだけ。
    - 基本的にはビデオ会議で英語で話して英語で聞く感じ。
- 音声コミュニケーションの問題
    - 自動字幕は出るが、消えるのが早い
    - ブラウザ上で選択することができない
    - なので英語のネイティブスピーカーでない僕が機械翻訳を使うことが妨げられている
    - チャットのように全て残ればいい
    - 理想としては機械翻訳をシステム自体に統合するのが良い
    - ノーベル賞サミットだからもうちょっと「世界中から参加者がいる」ということをケアする仕組みがあるかと思ったがそんなものはなかった
- 2回のセッションが終わって思ったこと
    - 音声による[[ターン制コミュニケーション]]が諸悪の根源では
        - [[音声コミュニケーション]]は一度に一人しか出力できない
        - 一人の人が話しすぎないように中断したりする仕組みが用意されているが、それが必要なのは音声を使っているから
        - 音声をやめてみんなテキストで並列で書けばいいのに
- 寝て起きて気づいたこと
    - これは同じことを違う視点から見ている
    - 動画で論点を見せて、口頭で話し合う仕組み(今回のもの)
        - これは「文章の読み書き能力が低い人でも熟議のプロセスに参加できるようにしよう」という仕組み
        - しかし、英語での音声コミュニケーションが苦手な人は疎外される
    - テキストで非ターン制議論をする仕組み
        - これは参加者の文章読み書き能力が十分高いと仮定してる
        - 音声を聞くことや声を出すことが苦手な人でも議論に参加できるようになる仕組み
        - しかし、テキストコミュニケーションが苦手な人は疎外される
    - 結局これは個々人の多様な認知特性に寄り添うことだから両方の仕組みが必要なのではないか
        - でも僕の認知特性は「テキスト非同期コミュニケーションの方が圧倒的にいい」派なので、僕が音声サイドの支援をするプロジェクトをするのは向いてないと思う

[[熟議の全体像]]
