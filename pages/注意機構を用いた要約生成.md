---
title: "注意機構を用いた要約生成"
---

[[注意機構]]を用いた[[要約生成]]  #要約
[[深層学習による自然言語処理]] p.136
[A Neural Attention Model for Abstractive Sentence Summarization](https://arxiv.org/abs/1509.00685)

[[注意機構]]
RNNではなく、固定長Cの順伝播ネットワークを使った
- 後の研究でRNNの方が精度が良いとされてるのでこれは最初に生まれた時はそうだったという歴史的な話に過ぎない
文脈長Cを用いて $Y_< = Y_{[j-C,\, j-1]}$とする
入力文Xに対して要約文出力Yがでる条件付き確率はこう書ける。
$P(Y|X) = \prod_j P(y_i | X, Y_<)$
$P(y_i | X, Y_<) = \mathrm{softmax}(\tilde{o_j})\cdot y_j$
$\tilde{o_j} = \mathrm{nnlm}(Y_<) + \mathrm{enc}(X, Y_<)$

![image](https://gyazo.com/f0fdaffe41b8b0cf70ccca0b8595c7ac/thumb/1000)
![image](https://gyazo.com/6f0f768522bc299f78caf8ea07e6274e/thumb/1000)
