---
title: "双シェマモデル プレゼン"
---

## [[強化学習]] その5
# 双シェマモデル
- 2017-07-14 @ [[機械学習勉強会]]
- サイボウズ・ラボ 西尾泰和


双シェマモデルとは
- [[谷口忠大]], [[椹木哲夫]]. "[[双シェマモデル]]." 人工知能学会論文誌 19.6 (2004): 493-501.
- 副題 [[自律エージェントの為の自己組織化機械学習手法の提案]]

- まず発達心理学サイドの話
- それから学習アルゴリズムの話


シェマって？
- [[Piaget]]の[[シェマ理論]]
- [[schema]]のフランス語読み
- 発達心理学分野ではシェマ、認知科学や人工知能の研究では[[スキーマ]]と訳される


Piagetのシェマ理論
- [[シェマの均衡化]]・分化のプロセスを通して
- シェマの外界に対する対応が詳細化する
- シェマは離散的・有限個
- シェマが作られていく過程が
    - 対象を離散な記号で表現する
    - ボトムアップな言語の獲得


均衡化と分化
- まず均衡化から詳しく説明する
- 均衡化は同化と調節の2つのプロセスからなる
    - 同化： シェマに外界からの情報を取り込む
        - どのシェマに取り込むかの選択が行われる
    - 調節： 外界からの情報を取り込むためにシェマを変化させる


[[k平均法]]と比較してみると
- データは最も近い代表点を持つクラスタに分類される
    - = 同化： シェマに外界からの情報を取り込む
        - どのシェマに取り込むかの選択が行われる
- クラスタの代表点はクラスタに分類されたデータの平均値に更新される
    - = 調節： 外界からの情報を取り込むためにシェマを変化させる
- この場合 [[クラスタ = シェマ]]


[[シェマの分化]]
- 均衡化のプロセスはk平均法のように「固定クラスタ数のクラスタリング」はできる
- しかしクラスタ数は変化しない
- 分化のプロセスで新しいシェマが作られる
- 既存のシェマとかけ離れたデータが入ってきたときに新しいシェマを作る、これが分化


双シェマとは
- ピアジェのシェマ理論を元にした、
- 自立ロボットが環境との相互作用を通して
- 環境・対象のモデルに相当するシェマ（概念）を獲得する
- 累積型モジュール学習器 (2005)

- 谷口忠大, and 椹木哲夫. "[[身体と環境の相互作用を通した記号創発]]." システム制御情報学会論文誌 18.12 (2005): 440-449.
    - [[環境との相互作用]] / [[身体と環境の相互作用]] / [[記号創発]]

ロボット
- センサとモータを持っているロボットを想定
    - センサ入力は有限次元の実数値ベクトル
    - センサ入力を元に、内部処理系が意思決定し、行為出力を出す
    - 行為出力は数次元の実数値ベクトル


時刻tにおける値
- センサ入力、知覚ベクトル: $S_t$
- 行為出力、行為ベクトル: $A_t$
- 経験ベクトル $U_t = (A_t, S_t, S_{t+1})$


双シェマ
- ビアジェのシェマを[[知覚シェマ]]と[[行為シェマ]]に分割
- 知覚シェマ: $\hat{F}=(F,\alpha): A_t = F(S_t, I_{t+1}) + \alpha\delta_t$
- 行為シェマ:  $\hat{G}=(G, \beta): I_{t+1} = G(S_t) + \beta\delta_t$
    - ここで$I_{t+1}$ は時刻 t+1において主体が得たいと思う知覚([[意図]]: Intention)
    - 理想的には$S_{t+1} \simeq I_{t+1}$
    - : $\delta$は乱数


行為のプログラム
- この2つの組み合わせで外界からの入力から行為を選択する
    - 行為のプログラムとはSからAを決める関数である $A_t = H(S_t)$
    - これは2つのシェマの組み合わせでこう書ける$A_t = F(S_t, G(S_t))$


同化
- 経験ベクトル $U_t$ が知覚シェマの関数Fを満たすかどうか
- これが、そのシェマが外界に存在する対象を表象する記号として適切かどうか、に対応
- = 同化のプロセス
- モデル誤差$(A_t - F(S_t, S_{t+1}))^2$ が小さければ、対象はFを持つ知覚シェマに属する
    - そこの誤差を取るんだ？ $(S_{t+1} - I_{t+1})^2$ではなくて？<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
    - (2005)ではそれのL1ノルムになってた
- 誤差が大きいとどのシェマにも入れずに捨てて、それが続くと新しいシェマを作るけどそれは分化のプロセスなのでここでは説明しない


調節
- 各シェマは有限のキューを持つ
- このキューに経験ベクトル$U_t$が格納されていく
    - いっぱいになると古い方から忘れる
    - 著者らはこの[[記憶容量の有限性]]が重要だと主張している
- シェマに入った経験ベクトルを最小誤差で近似できるように内部関数を更新する
    - ちなみに(2004)では線形近似＋最急降下法


均衡化プロセス=教師なし学習器
- 論文(2004)では均衡化プロセス(同化+調節)が教師なし学習器として機能することを物理的ロボットを使った実験で検証しているけども、まあ特に異論ないよね
- 分化のプロセスを見よう


分化のプロセス
- ずれてると新しいシェマが作られる
- 「ずれ」についての定義が必要
- 誤差 $E_{U_t} = ||A_t - F(S_t, S_{t+1})||$
- 誤差平均 $E_{F,G} = \frac{1}{\# \mathcal{U}_{F, G}} \sum_{U_t \in \mathcal{U}_{F, G}} E_{U_t}$
- [[主観的誤差]] $R_{F, t} = E_{U_t} / E_{F, G(t)}$
    - なおFが知覚シェマ


ずれ
- 新しい経験$U_t$が知覚シェマ$F_n$からずれてる時、原因は3つある
    - 1: 現在の環境についての学習が不十分
        - つまり均衡化不足
    - 2: ノイズが一時的に入ってきた
    - 3: 均衡化した時の環境と、別の環境になった

ずれへの対応
- 1: 現在の環境についての学習が不十分
    - 1: 主観的誤差の分母も大きくなるので主観的誤差は大きくならない
- 2: ノイズが一時的に入ってきた
    - 新しいシェマを作るべきでない
    - しばらく観察する必要がある
- 3: 均衡化した時の環境と、別の環境になった
    - 新しいシェマを作る


新しいシェマを作るか？
- [[知覚シェマ活性度]](2005)
- $V_n(t+1) = pV_n(t) + (1-p)\exp(-\frac{1}{2}R_n(t)^2)$
- (1) すべての知覚シェマの活性度があらかじめ定めた閾値$V_{turn}$ を超えなければ、適切なシェマがないってことなので、新しいシェマを作る
- (2) otherwise 知覚シェマが閾値以上のものから最も古いものを選択する
    - 最も活性度が高いとか誤差の小さいものではなくて？<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>
    - 「誤差最小のモジュールを選択する、では決してない」とか書いてるから意図的なものなのだろう…
    - Q: 「古い」とは？ A: 最も先に作られたシェマ
- (2004)でのシェマ活性度の定義は若干違うのだが、説明に「$\Phi$ は $\Phi(0) > 0$ かつ $\Phi(\infty) < 0$ の条件を満たす単調増加関数」と書いてあって意味がよくわからないのでパスした


実験した分化の流れ
- ロボットに静止している玉を見せる
- 均衡化が進んで静止している玉を注視できるようになる
- 玉を左右に動かす
- シェマの活性度が下がる
- 新しいシェマが作られる
- 左右に動く球に対して均衡化が行われる


著者らの主張([[距離情報からカテゴリ化を行うことの問題]])
- 「ここで重要なのはセンサ入力空間における距離情報からカテゴリ化を行ったのではないということである」
- 距離を与えて(もしくは無自覚にユークリッド距離などを仮定して)クラスタリングする手法では、結局何を重視すべきかを外部から与えている形になる
- そうではなくロボット自身が自分の経験から概念の分割を行ったところが大事、という感じ


強化学習との関係
- (2004)、(2005)ではどちらでも行為シェマを人間が与えている。
    - ボールを視野の真ん中でとらえようとする行為シェマを与えている。
- (2006)では強化学習で獲得しようとする
    - 強化学習では何を良いとするかを報酬として与えることになる
        - 板の上に乗ったボールのコントロールで、真ん中に近いほど高い報酬を与えている。
    - あんまり違わない気もする…。

- (2006) [[汎化行為概念の適応的獲得]]
    - 谷口忠大, and 椹木哲夫. "汎化行為概念の適応的獲得." 計測自動制御学会論文集 42.3 (2006): 255-264.


[[作られるシェマの量と身体能力の関係]]
- 身体的能力が高くても低くてもあまりシェマが作られない
- 中くらいの時に一番たくさん作られる(2005)
![image](https://gyazo.com/7d28dd595d1a76509ec651bc618f7cf6/thumb/1000)


作られるシェマの量と身体能力の関係
- 視野が広いor時間解像度の高いロボット
    - ボールがどこにあるか見えてる
    - ボールがあるところを注視すればよい
    - ボールの動作パターンをシンボル化する必要がない
- 中くらいのロボット
    - ボールは見えているが、すぐ見失う(たぶん)
    - ボールの動作パターンを理解すると「今は円運動モードだから次はこのあたりにあるはずだ」ができる
    - シンボルを作ることで性能が向上する
- 性能の低いロボット
    - ボールを見失ってばっかりで意味のある動作パターンを発見できない


人類の言語と機械の言語
- 人類と機械には大きな身体能力の差がある
- その差が原因で、作られる言語に差が出そう
- 人間は「リンゴである」「リンゴでない」とBooleanで考えるが、
- 機械は「リンゴである確率が0.8、ナシである確率が0.2のもの」と実数ベクトルで考えられる
- [[人間はベクトル演算が弱い]]、ベクトルを言葉で伝えられない。機械は逆
- [[身体能力の高いロボットは言語を作る必要がない]]


機械の視点から
- 能力の劣った生き物が能力をなんとか高めようとして作り出した複雑な記号体系
- これを理解してやる必要はあるのだろうか…(自然言語処理は必要なのか？)
- 自分の得意分野に専念して価値を作り出して、それを自分の言葉で彼らに伝えればよいのでは
- 価値が明確であれば、自分の言葉を理解することに彼らが投資するだろう


グループウェアのドメインに応用する
- 元の研究はロボット
- グループウェアに応用する上で「[[身体性]]」とは何か
- 外界を操作し影響を与えるとは限らない
    - 今回の実験ではカメラを動かしてるだけ
- 自分の出力によって自分のセンサー入力に影響を与えている


[[選好注視法]]
![image](https://gyazo.com/4d50d5f630dd97a02f0d2b343670a551/thumb/1000)
- 乳児でも複数の入力のどちらか片方を注視することができる
- より好んでいるものを注視するとされている


選好注視法
- 複数の情報源の詳細ではない情報を得て、どちらの情報をより詳細に入力するかを選ぶ
    - 自然言語処理の普通のセンスだと「選択しないで全部入れたらいいのでは」と思うが、全データを扱えるって仮定は「身体的能力のとても高いロボット」に相当するので、それだと記号を創発しないだろう。
- 例えばWikipediaの今注視しているページからのリンクのタイトルを得て、そこから「次にどのページを見るか」を選ぶ
    - 「Français」ってリンクを避けるようになる？
- 例えばグループウェア投稿の、字数とか文字種ごとの出現頻度から、どれを詳細に見るか選ぶ
    - ログ出力を貼りつけた物とかを避ける？


[[行為シェマ]]
- 避けるのか好むのかは行為シェマ次第
- (2004)では「ボールを視野中央でとらえる」という行為シェマを与えている
- (2006)でも強化学習で行為シェマを獲得させるにあたって、[[報酬]]を人間が定義して与えている
- もしくは人間が事前に定義するのではなく、ランダムな結線のニューラルネットで1次元実数値を出して報酬ってことにする
    - =[[生まれつきの好み]]
- ランダムタイプを100匹くらい育てて、人間にとって都合の悪い振る舞いをするやつを殺して、残ったやつを交配させる
    - ダーウィン的な[[自然淘汰による最適化]]


まとめ
- ロボットが環境との相互作用を通して概念を獲得する「双シェマモデル」について学んだ
- 物理的身体を持たないソフトウェアにも身体性を持たせることはできそう
- 言語の創発を観察するのは面白そう
    - 人間にとって実用的であることとの間にはまだまだギャップがある
- 身体能力が高いと言語が生まれない
    - 人間と身体能力が大きく異なる機械が仮に言語体系を生み出したとしても、それはおそらく人間の言語体系とは大きく異なる(日本語と英語の差が小さく見えるくらい)
    - その言語を人間が理解するのは、日本語と英語の翻訳よりもさらに苦労するだろう


参考文献
- (2004) 双シェマモデル
    - 谷口忠大, and 椹木哲夫. "双シェマモデル." 人工知能学会論文誌 19.6 (2004): 493-501.
    - 副題 自律エージェントの為の自己組織化機械学習手法の提案
- (2005) 身体と環境の相互作用を通した記号創発
    - 谷口忠大, and 椹木哲夫. "身体と環境の相互作用を通した記号創発." システム制御情報学会論文誌 18.12 (2005): 440-449.
- (2006) 汎化行為概念の適応的獲得
    - 谷口忠大, and 椹木哲夫. "汎化行為概念の適応的獲得." 計測自動制御学会論文集 42.3 (2006): 255-264.
