
hatena

```
<body>
*1390901484*AICを線形回帰で実験的に確認
予測に使うパラメータが増えると、たとえそれがただのノイズで真のモデルには一切出てこないデータであったとしても、訓練データに対しての当てはまりはよくなる。しかしもちろん、テストデータに対しての当てはまりは悪くなる。

というわけで線形回帰で1～5個のパラメータから正解tを予想するモデルで実験してみた。tは1個目のパラメータにノイズを乗せたもので、2～4番目のパラメータはまったく影響しない。しかしそれでも、予測に使うパラメータが1個増えるごとに、訓練データに対する対数尤度はおよそ0.5ずつ上昇する。

>[ 0.          0.49161953  0.99283812  1.47318384  1.9262704 ]
 
一方で、テストデータに対しての対数尤度はパラメータが1個増えるごとにおよそ0.5ずつ減少する。

>[ 0.         -0.55409662 -1.11481264 -1.66386383 -2.08548524]

つまり、パラメータが1個増えるごとに差は1ずつ増える。AICで、訓練データに対する対数尤度からパラメータの個数を引いたものを最大化するのは、テストデータに対する対数尤度を推定して最大化していることになるわけだな。

ソースはこちら: https://gist.github.com/nishio/8595089
</body>
```


[はてなダイアリー 2014-01-28](https://nishiohirokazu.hatenadiary.org/archive/2014/01/28)