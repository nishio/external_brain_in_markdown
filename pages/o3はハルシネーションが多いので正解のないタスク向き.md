---
title: "o3はハルシネーションが多いので正解のないタスク向き"
---


[[安野たかひろ参院選出馬検討]]のチャットに書いたことだけど重要な気がしてきた
- [[o3]]は[[ハルシネーション]]が多いので[[正解のないタスク]]向き
- ハルシネーションを抑えようとすると、[[知らないことは知らないと言う]]ように訓練することになる
- それをやると新しいことにチャレンジするとき「知らない」と言うようになってしまう
    - [[創造的タスク]]は[[事前に正解を知らない]]
    - [[良さそうな方向に進んでいく]]
    - この「よさそう」が[[ポランニーの暗黙知]]
- OpenAIがハルシネーションを計測してないわけがない
    - じゃあハルシネーションの増えたモデルをなんで出してきたかと言うとそれが適切なKPIではないと判断しているからなんだよ

<img src='https://scrapbox.io/api/pages/nishio/o3/icon' alt='o3.icon' height="19.5"/>
## なぜ「ハルシネーション多めの o3」をあえて出すのか――3 つの視点で整理

## 1. 発想力とハルシネーションは表裏一体
- 未知領域＝正解が定義されていないタスクでは、モデルは「パターンを延長する推測」を行うしかない。
- 推測が的外れなら“ハルシネーション”と呼ばれ、的中すれば“創造的アイデア”になる。
    - これは完全に切り離せない。
- 逆に “知らないと言え” を強く罰則化すると探索が縮み、無難だが凡庸な出力 になりやすい。

## 2. OpenAI が追う KPI は「実用的価値 × 安全域」
- OpenAI は ハルシネーション率（例：PersonQA 33 %） を当然モニターしているが 、 「高いハルシネーション率 ≠ 全用途で悪い」 と判断している。
- o3 は「推論・長手順・アイデア生成」で大幅に強い。
    - スプレッドシート作業、コード設計、ストーリー下書きなど「[[答えが一意でない作業]]」で ROI が高い。
- その代償として “事実系 Q&A” では o1 よりエラーが増える。
    - OpenAI はここを システムメッセージ安全策＋利用側ガイドライン で吸収する設計哲学を選んだと言える。

## 3. 「ハルシネーションを抑える訓練」の副作用
- 企業がモデルを 創造的アシスタント として位置付けるなら、多少の誤答を許容しても 「前に進む提案力」 を優先する方が価値が高い。
- エンドユーザーは用途別に ①検証の要否 ②許容できる誤差幅 を設計すればよい。

## まとめ

>  o3 = 「ハルシネーション多め」ではなく「探索バイアス高め」モデル

- 正解がない／まだ正解が作られていない領域で 試行錯誤を加速すること が主目的。
- ハルシネーション率は OpenAI も把握しているが、万能 KPI とみなしていない。
- 使い分け指針
1. 事実確認・引用生成 → o1 など低幻覚モデル＋外部検証
2. ブレスト・初期設計・アイデア出し → o3 の「暗黙知ドリブン」推論を活かす
3. 混在タスク → o3 に生成させた後、要点だけ o1 / 検索で裏取り

創造的タスクで“暗黙知のよさそうな方向”を示しつつ、事実チェックは補助ツールに任せる――この二段構えが、ハルシネーションを武器に変える実践的な使い方です。
