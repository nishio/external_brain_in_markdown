---
title: "LangChain Glossary"
---

[[LangChain]] Glossary
[Glossary â€” ğŸ¦œğŸ”— LangChain 0.0.120](https://langchain.readthedocs.io/en/latest/glossary.html)
- Chain of Thought Prompting
    - A prompting technique used to encourage the model to generate a series of intermediate reasoning steps. A less formal way to induce this behavior is to include â€œLetâ€™s think step-by-stepâ€ in the prompt.
    - [[Chain of Thought]]
    - [[Step-by-Step(LLM)]]

- Action Plan Generation
    - [[ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆ]]
    - A prompt usage that uses a language model to generate actions to take. The results of these actions can then be fed back into the language model to generate a subsequent action.
    - Resources:
        - WebGPT Paper
        - SayCan Paper

- ReAct Prompting
    - [[Chain of Thought]]ã«[[ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆ]]ã‚’çµ„ã¿åˆã‚ã›ãŸã‚‚ã®
    - A prompting technique that combines Chain-of-Thought prompting with [[action plan generation]]. This induces the to model to think about what action to take, then take it.
    - [[ReAct(LLM)]]
    - LangChain Example

- Self-ask
    - æ˜ç¤ºçš„ã«è³ªå•æ–‡ã‚’ç”Ÿæˆã•ã›ã€å¤–éƒ¨ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ã†
    - A prompting method that builds on top of chain-of-thought prompting. In this method, the model explicitly asks itself follow-up questions, which are then answered by an external search engine.
    - Resources:
        - [[self-ask]]
        - LangChain Example

- Prompt Chaining
    - Combining multiple LLM calls together, with the output of one-step being the input to the next.
    - Resources:
        - PromptChainer Paper
        - Language Model Cascades
        - ICE Primer Book
        - Socratic Models

- Memetic Proxy
    - å½¹å‰²ã‚’æ¼”ã˜ã•ã›ã‚‹ã“ã¨ã§ç‰¹å®šæ–‡è„ˆã§ã®æŒ¯ã‚‹èˆã„ã‚’ã•ã›ã‚‹
    - Encouraging the LLM to respond in a certain way framing the discussion in a context that the model knows of and that will result in that type of response. For example, as a conversation between a student and a teacher.
    - Resources:
        - Paper

- Self Consistency
    - A decoding strategy that samples a diverse set of reasoning paths and then selects the most consistent answer. Is most effective when combined with Chain-of-thought prompting.
    - Resources:
        - Paper

- Inception
    - Also called â€œFirst Person Instructionâ€. Encouraging the model to think a certain way by including the start of the modelâ€™s response in the prompt.
    - Resources:
    - Example

- MemPrompt
    - MemPrompt maintains a memory of errors and user feedback, and uses them to prevent repetition of mistakes.
    - Resources:
    - Paper

