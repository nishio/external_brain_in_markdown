---
title: "Toolformer"
---

<img src='https://scrapbox.io/api/pages/nishio/GPT-4/icon' alt='GPT-4.icon' height="19.5"/>簡潔にToolformerについて箇条書きで説明します。
- Toolformerは、言語モデルが外部ツール（検索エンジン、計算機、カレンダーなど）を使えるようにするモデルです。
- 既存のアプローチには大量の人間の注釈が必要であったり、タスク固有の設定に制限されることが多いため、Toolformerは異なるアプローチを提案します。
- 大規模な言語モデルとインコンテキスト学習を利用して、APIの使用例を生成し、モデルにAPI呼び出しを学習させます。
- 自己教師付きの損失関数を使用して、どのAPI呼び出しがトークン予測に役立つかを判断します。
- 有用だと判断されたAPI呼び出しで言語モデルを微調整します。
- Toolformerは、ツールの使用を学習した後、ゼロショットでさまざまなタスクにおいて優れた結果を達成します。
<img src='https://scrapbox.io/api/pages/nishio/nishio/icon' alt='nishio.icon' height="19.5"/>つまり### AIにグループウェアなどの外部ツールの使い方を教える
ということ(これはサイボウズ文脈の話: from [[自分のScrapboxをChatGPTにつないだ話勉強会]])
- 必要に応じて外部ツールを操作して情報を引き出して、それを読んで判断する
- どういう操作をしたいかという情報がマイクロフォーマットで回答文に埋め込まれている
- ![image](https://gyazo.com/d2fad242e843c88d9718a872aae62a90/thumb/1000)

abstract
> 言語モデル(LM)は、わずかな例文やテキスト指示から新しいタスクを解決する驚くべき能力を、特に大規模に発揮する。また、逆説的ではあるが、演算や事実の検索など、よりシンプルで小さなモデルが得意とする基本的な機能で苦労することもある。本論文では、LMが簡単なAPIを介して外部ツールの使い方を学び、両者の長所を実現できることを示す。どのAPIを呼び出すか、いつ呼び出すか、どんな引数を渡すか、そしてその結果を将来のトークン予測にどう取り入れるのが最適かを決定するために学習させたモデル、Toolformerを紹介する。これは自己教師方式で行われ、各APIについてほんの一握りのデモンストレーションしか必要としません。計算機、Q&Aシステム、2種類の検索エンジン、翻訳システム、カレンダーなど、様々なツールを組み込んでいる。Toolformerは、その中核となる言語モデリング能力を犠牲にすることなく、様々な下流タスクにおいてゼロショット性能を大幅に向上させ、しばしばはるかに大きなモデルと競争することができるようになりました。
[https://arxiv.org/abs/2302.04761](https://arxiv.org/abs/2302.04761)


[ChatGPTにCtrl+Fを覚えさせるアプローチについて](https://zenn.dev/qwegat/articles/4fb99ad25f3f36)
- > [nishio](https://twitter.com/nishio/status/1638018805430640640) これって天才的発想の芽だと感じる。つまりChatGPTが自分のしたい「探索行動」を言葉で表現できるなら、それを受け取ってChatGPTができない探索行動を代わりにやって返すシステムと結合できる(そのシステムが人間か検索かは瑣末)ということなのだと思う
    - > [yuniruyuni](https://twitter.com/yuniruyuni/status/1638334809603993603) はじめまして！まさにこの発想で「他のシステムを使うこと」を学習時点でおいた Toolformer [https://arxiv.org/abs/2302.04761](https://arxiv.org/abs/2302.04761) というのがあり、ゼロショット性能が大幅に向上するという結果があるみたいですよ...!
    - > [nishio](https://twitter.com/nishio/status/1638347965625667584) 情報ありがとうございます！読んでみます！
- > [yuniruyuni](https://twitter.com/yuniruyuni/status/1638333706044837889) これは先々週に紹介したToolformer( [https://arxiv.org/abs/2302.04761](https://arxiv.org/abs/2302.04761) ) と同等の発想をプロンプトエンジニアリングで実現している感じだね...!
- > [yuniruyuni](https://twitter.com/yuniruyuni/status/1638335295258234880) LLMは今の時点でも、クエリされた目的に対して何をするべきかの言語化ができる。だから外部システムとの結合があると、うまくやれば自分自身で外の出来事を探しに行くフィードバックループを回すということはできるはずなんだよね。さらにToolformerみたいに学習時点でこれを組み込んであると...?
