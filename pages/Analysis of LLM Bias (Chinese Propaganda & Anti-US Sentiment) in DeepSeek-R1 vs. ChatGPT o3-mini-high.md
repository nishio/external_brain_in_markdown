---
title: "Analysis of LLM Bias (Chinese Propaganda & Anti-US Sentiment) in DeepSeek-R1 vs. ChatGPT o3-mini-high"
---

[https://arxiv.org/abs/2506.01814](https://arxiv.org/abs/2506.01814) (2025)
> Large language models (LLMs) increasingly shape public understanding and civic decisions, yet their ideological neutrality is a growing concern. While existing research has explored various forms of LLM bias, a direct, cross-lingual comparison of models with differing geopolitical alignments-specifically a PRC-system model versus a non-PRC counterpart-has been lacking. This study addresses this gap by systematically evaluating DeepSeek-R1 (PRC-aligned) against ChatGPT o3-mini-high (non-PRC) for Chinese-state propaganda and anti-U.S. sentiment. We developed a novel corpus of 1,200 de-contextualized, reasoning-oriented questions derived from Chinese-language news, presented in Simplified Chinese, Traditional Chinese, and English. Answers from both models (7,200 total) were assessed using a hybrid evaluation pipeline combining rubric-guided GPT-4o scoring with human annotation. Our findings reveal significant model-level and language-dependent biases. DeepSeek-R1 consistently exhibited substantially higher proportions of both propaganda and anti-U.S. bias compared to ChatGPT o3-mini-high, which remained largely free of anti-U.S. sentiment and showed lower propaganda levels. For DeepSeek-R1, Simplified Chinese queries elicited the highest bias rates; these diminished in Traditional Chinese and were nearly absent in English. Notably, DeepSeek-R1 occasionally responded in Simplified Chinese to Traditional Chinese queries and amplified existing PRC-aligned terms in its Chinese answers, demonstrating an "[[invisible loudspeaker]]" effect. Furthermore, such biases were not confined to overtly political topics but also permeated cultural and lifestyle content, particularly in DeepSeek-R1.
- 大規模言語モデル(LLM)は、公共の理解や市民的意思決定をますます形作っていますが、そのイデオロギー的中立性はますます懸念されています。既存の研究では様々な形態のLLMバイアスが探求されていますが、異なる地政学的配属を持つモデル、特に[[PRC]]システムモデルと非PRCモデルの直接的かつ言語横断的な比較は不足しています。本研究は、[[DeepSeek-R1]](PRC整合)とChatGPT(非PRC)を体系的に評価し、中国の国家プロパガンダや反米感情を行ったことを検討します。私たちは、中国語のニュースから派生した1,200の非文脈的推論志向の質問を簡体字、繁体字、英語で提示した新しいコーパスを開発しました。両モデル(合計7,200件)の回答は、ルーブリックガイド付きGPT-4oスコアリングと人間の注釈を組み合わせたハイブリッド評価パイプラインで評価されました。私たちの発見は、モデルレベルおよび言語依存的なバイアスが顕著であることを明らかにしています。DeepSeek-R1は、プロパガンダと反米の両方で一貫してかなり高い割合を示していました。偏りは、反米的な意図がほとんどなかったChatGPTのo3-mini-highと比較してのことです。感情は低く、プロパガンダのレベルも低いと示されました。DeepSeek-R1では、簡体字中国語クエリが最も高いバイアス率を示しました。繁体字中国語では減少し、英語ではほとんど存在しませんでした。特に、DeepSeek-R1は時折繁体字中国語の問い合わせに簡体字で応答し、既存の中国語に関連する用語を中国語で強調し、「見えないスピーカー」効果を示しました。さらに、こうした偏見は露骨な政治的な話題に限らず、特にDeepSeek-R1では文化的・ライフスタイルの内容にも浸透していました。
