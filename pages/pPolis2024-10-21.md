---
title: "pPolis2024-10-21"
---

from [[pPolis2024-05-27]]
pPolis2024-10-21
2024-10-21
:

```
[f"{x * 100:.1f}%" for x in pca.explained_variance_ratio_]
```

:

```
['29.1%', '18.8%', '7.5%', '5.1%', '3.2%', '3.0%', '2.4%', '2.1%', '2.0%', '1.7%', '1.6%', '1.5%', '1.3%', '1.3%', '1.2%', '1.2%', '1.0%', '1.0%', '1.0%', '0.9%', '0.9%', '0.8%', '0.8%', '0.8%', '0.8%', '0.8%', '0.7%', '0.7%', '0.7%', '0.6%', '0.6%', '0.6%', '0.6%', '0.6%', '0.5%', '0.5%', '0.5%', '0.4%', '0.4%', '0.4%', '0.4%', '0.0%']
```

len = 42

> >> pca.n_features_in_
592

> >>pca.n_samples_
42

はー、そうか
- 転置してからPCAしてるなと思ったがそういうことか
- <img src='https://scrapbox.io/api/pages/nishio/gpt/icon' alt='gpt.icon' height="19.5"/>
    - 転置しない場合: 質問間の共分散を計算し、各質問が新しい基底（主成分）にどれだけ寄与しているかを示します。質問同士の関係性を探る場合に有効です。
    - 転置する場合: 回答者間の共分散を計算し、各回答者が主成分にどれだけ寄与しているかを示します。回答者のクラスタリングやパターンの発見に有効です。
- 回答者のクラスタリングをしたいわけなのでそれが正しい

P=592 (people)
Q=42 (questions)
> embedding.shape # (592, 2)

<img src='https://scrapbox.io/api/pages/nishio/gpt/icon' alt='gpt.icon' height="19.5"/>転置して回答者間の共分散を用いたPCAを行った場合、ある質問 i の解答が、PCA後のX軸にどう寄与するかを考えるには、まずその質問 i が回答者全体の主成分にどう影響しているかを確認する必要があります。

![image](https://gyazo.com/c293eda93f7f43d71acbada073db47fd/thumb/1000)
あってると思う

![image](https://gyazo.com/61b2fcb02c10d7017e2826609e7a2fc3/thumb/1000)
列とはどちらなのかはさておき、あってると思う

![image](https://gyazo.com/ce35f6cf32917e58a8e38fab39f52139/thumb/1000)

py

```
# PCA成分の取得
matrix_centered = matrix - matrix.mean(axis=0)  # 平均中心化
# pca.fit(matrix_centered.T)  # 回答者に基づいてPCAを実行

# 第1主成分（X軸）
pc1 = pca.components_[0]  # 第1主成分ベクトル（回答者ごとの重み）

for col in matrix.columns:
    question_vector = matrix_centered[col]
    # contributions[col] = np.dot(question_vector, pc1)
    c = np.dot(question_vector, pc1)

    print(f"{col}: {c:.2f}: {readable.get(col, col)}")
```

データはできた

[[AIに主成分軸を解説させる実験]]
