---
title: "Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models"
---

[2404.03622 Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models](https://arxiv.org/abs/2404.03622)
<img src='https://scrapbox.io/api/pages/nishio/Claude/icon' alt='Claude.icon' height="19.5"/>この論文では、大規模言語モデル(LLM)の[[空間推論能力]]を向上させるために、[[Visualization-of-Thought]] (VoT)というプロンプティング手法が提案されています。主な内容は以下の通りです。
1. VoTは、人間の「[[心の目]]」による[[空間推論]]をLLMに模倣させる手法である。推論ステップごとに[[可視化]]を行い、後続のステップを導くことで空間推論を引き出す。
2. 自然言語ナビゲーション、ビジュアルナビゲーション、ビジュアルタイリングの3つのタスクでVoTの有効性を評価した。VoTはこれらのタスクでLLMの空間推論能力を大幅に向上させ、既存のマルチモーダルLLMを上回る性能を示した。
3. 2Dグリッド世界の「ビジュアルナビゲーション」と「ビジュアルタイリング」の2つの新しいタスクとデータセットを開発した。これらは複雑さを変化させた空間推論の研究に適したテストベッドとなる。
4. VoTによる[[メンタルイメージ生成]]は人間の心の目に似ており、マルチモーダルLLMへの応用可能性が示唆された。
5. GPT-4を用いた実験により、VoTの有効性が実証された。LLMのメンタルイメージ生成能力の定量的・定性的分析を行い、その限界についても考察した。

[[心象風景]]を使った思考をLLMにエミュレートさせる方法
- これができるなら現状のLLMでも[[KJ法]]ができるのでは
