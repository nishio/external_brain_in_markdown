---
title: "深層学習による自然言語処理"
---

![image](https://gyazo.com/bb45d0ef28f156cfa28d7b75ae6a44e5/thumb/1000)
- [Amazon](https://amzn.to/2WIKeLd)

[https://www.kspub.co.jp/book/detail/1529243.html](https://www.kspub.co.jp/book/detail/1529243.html)

第1章　[[自然言語処理]]のアプローチ
1.1 伝統的な自然言語処理
1.2 [[深層学習]]への期待
1.3 テキストデータの特徴
1.4 他分野への広がり

第2章　ニューラルネットの基礎
2.1 教師あり学習
2.2 順伝播型ニューラルネット
2.3 活性化関数
2.4 勾配法
2.5 誤差逆伝播法
2.6 再帰ニューラルネット #RNN
2.7 ゲート付再帰ニューラルネット
- [[LSTM]]
- [[GRU]]
2.8 木構造再帰ニューラルネット
- [[recursive neural networks]] = [[Tree-RNN]]
2.9 畳み込みニューラルネット #CNN

第3章　言語処理における深層学習の基礎
3.1 準備：記号の世界とベクトルの世界の橋渡し
3.2 言語モデル
3.3 [[分散表現]]
- [[LBL model]] [[対数双線形モデル]]
- [[word2vec]] [[skip-gram]] [[CBoW]]
3.4 系列変換モデル
- [[seq2seq]]

第4章　言語処理特有の深層学習の発展
4.1 [[注意機構]]
4.2 [[Memory Network]]
4.3 出力層の高速化

第5章　応用
5.1 機械翻訳
5.2 文書要約
5.3 対話
5.4 質問応答

第6章　汎化性能を向上させる技術
6.1 汎化誤差の分解
6.2 推定誤差低減に効く手法
6.3 最適化誤差低減に効く手法
6.4 超パラメータ選択

第7章　実装
7.1 GPUとGPGPU
7.2 RNNにおけるミニバッチ化
7.3 無作為抽出
7.4 メモリ使用量の削減
7.5 誤差逆伝播法の実装
