
> What Is Roko's Basilisk?
>  In the summer of 2010, a user named Roko posted a short paragraph about an AI thought experiment to the LessWrong forums, a website where computer scientists, philosophers and nerds tend to hang out and discuss things.
>
>  In his post, Roko described a future where an all-powerful AI would retroactively punish anyone that did not help support or create it. Roko also added that this punishment would not apply to those that were and remain blissfully unaware of the AI's significance, which means that the biggest losers would be scientists that knew about the AI but willingly chose not to help create it.
>
>  VIRGIN "THE GAME" you've just lost it LOST THE GAME "the game haha you lost i'm so quirky" completely inconsequential not even a memetic hazard CHAD ROKO'S BASILISC if you know what it is you're definitely fucked failure results in eternal suffering "have you heard about roko's basilisk? what a retarded mind game unless" you have to do it's bidding now at least 5th level memetic hazard
>
>
>  Curiously, LessWrong forum founder Eliezer Yudkowsky immediately deleted the post and banned all further discussion of it for five years, calling the thought experiment an "information hazard." In a future interview, he said that he was shocked at the idea that "somebody who thought they'd invented a brilliant idea that would cause future AIs to torture people who had the thought, had promptly posted it to the public internet."
[https://knowyourmeme.com/editorials/guides/what-is-the-waluigi-effect-rokos-basilisk-paperclip-maximizer-and-shoggoth-the-meaning-behind-these-trending-ai-meme-terms-explained](https://knowyourmeme.com/editorials/guides/what-is-the-waluigi-effect-rokos-basilisk-paperclip-maximizer-and-shoggoth-the-meaning-behind-these-trending-ai-meme-terms-explained)
(DeepL)RokoのBasiliskとは？
2010年夏、Rokoというユーザーが、コンピュータ科学者や哲学者、オタクが集まって議論するウェブサイトLessWrongのフォーラムに、AIの思考実験に関する短いパラグラフを投稿しました。
Rokoは投稿の中で、万能のAIが、そのAIの支援や創造に協力しなかった人を過去にさかのぼって罰するという未来について述べています。つまり、最大の敗者は、AIの存在を知りながら、自ら進んでその創造に協力しないことを選んだ科学者たちということになる。
不思議なことに、LessWrongフォーラムの創設者であるエリエゼル・ユドコフスキーは、この思考実験を "情報ハザード "と呼び、すぐに投稿を削除し、それ以上の議論を5年間禁止しました。彼は後のインタビューで、"未来のAIがその考えを持った人を拷問するような素晴らしいアイデアを発明したと思った誰かが、早速それを公共のインターネットに投稿した "という考えにショックを受けたと述べています。
