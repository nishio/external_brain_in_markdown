

ラボユース合宿3日目
![image](https://gyazo.com/4085f4382269068f3ddd3b0e8387de53/thumb/1000)

既に出現したページを抑制するのは、ベクトル検索で出現したものに限定すべきだ
- ランダムでたまたま引いたけど関係ありそう、というとき、改めてその内容でベクトル検索して一番関連しているところを使うべきなので

[[AI読書ノート]]はとりあえず動いている
- ベクトル検索はしてない
- GPT-3.5で動かしてるんだけど、これ4Kまでなんだな
    - 16Kのバージョンを使うか
    - そうなると逆に「せっかく広いんだからもっと情報を入れてみよう」になるな
    - だが、そうなると「自分の書いたもの」に対する「読むもの」の割合が増えてしまい、自分がどんどん消えていくかも知れない
        - 多分そうなる
    - 結局は重要なのは自分のアウトプットの量
- あっ、3.5を使ってるつもりだったけど4だったw

ScrapboxへのIOを想定して、入出力の口は一つだけでエラーメッセージも同じところに来るのだけど、その仕組みだと機械的にループさせたらエラーメッセージを読んで続きを書いちゃいそうだね

あー、3.5だと読んだものをそのまま翻訳して書いてしまったりするなぁ
- 一度それをすると、それを見て次もやるからノートではなく翻訳みたいになってしまう

大雑把な概算で、1ステップに$0.48くらいかかって、一冊の本に100〜500ステップくらい掛かりそうだから、まあなかなか高いガチャだな

fill_with_related_fragments系が、今は与えられたトークンを埋める文字列と使ったページのタイトルのリストとを返してるけど、これが変わるべき
- なぜなら今のそれは「関連のあるものを積んで、残りにはランダムなチャンクを積む」という振る舞いになってる
- 今回の実装では半分の枠を渡して、余りと残り半分に本文のデータを流し込みたい
- 今の設計ではそういう柔軟性がないのがよくない
    - 序盤のインターフェースに縛られて密結合にすべきでないコードが一塊になっている

今日もまたpushし忘れて定期実行のコードがちょっと古い…
- pushしてmanual triggerするか

マルチヘッドでヘッドをたくさん増やしておこう
- 合宿からの帰りの電車でスマホで読むものを生成する的な話
- cronを1時間1回に変えた

離脱の時間までにできるかな
- ✅タイトルのパース
- ✅ベクトル検索のNGリストに積む
- ✅ベクトル検索の割合を増やす
    - 「最大3件」が「3件」に変わったのでとりあえずOK
    - 初期の、入力が少ない場合のバランス調整を将来的にやりたい
- ランダムで拾ったタイトルとベクトル検索で拾ったタイトルを区別する

会場離脱
- とりあえず並列ノートをたくさん作っておいた
- これは今日の夜には忘れずに止めないとな…
    - 1時間1回走るので明日の朝大変なことになってしまう
    - 今でも既に大変なことになってる説w
    - TODO 家に着いたら1日1回に戻す
- たくさんのテーマを並列で走らせるのは良い
    - 🔁マークを削れば自動更新は止まる
    - でも、明示的にマークを削るって行動はあんまり体験がよくないように思っている
    - ゆっくり頻度が下がっていくのがいいのでは？
        - [[Spaced Repetition]]
        - 徐々にスパンが増えていく
        - 人間がリアクションをしたら1日に戻る
    - 生成日時は表示されている
        - 生成日時よりも更新日時が後なら編集が行われたということなので次回の定期タイミングで更新
        - 更新されてない場合には「前回の生成とその前の生成の差分」に1.5を掛けたものを超えている場合にのみ更新
            - つまり1,2,3,5,8,13,という感じになる
            - だいたい[[フィボナッチ数列]]

エラーが出たときにフラグメントが全部出力されてしまうので、それを消してやらないといけない、スマホからやるのはとても面倒
- 消さなかった場合、次回もコンテキスト幅オーバーでエラーになるはず、これは実装が悪いw

今数えたら並列トピック20ページもあるじゃん、作りすぎ！
- 一部は今日ラボユースの人のLTを聞いて知ったキーワード
- 一部は長年言及し続けてきたキーワード
    - 一般的キーワードなのでGPT4も答えることができる
- 一部はKozanebaなどのキーワードなので生のGPT4が答えられないもの
    - 今のところScrapboxから情報を拾ってうまく答えてるね

16:07にリリースしましたの通知がGithubからくる、でもこの後GPT4が20件走るんだな、あれ？じゃあ30分くらいに上書きが走る？書き込みづらいな…
- やはり寝てる時間に動くべきだな

16:58 横浜駅で迷子になってる間に更新が来てるかなと思ったが来てなかった
- これは何らかのエラーで落ちてるかな？
- 落ちてすらいない！
    - ![image](https://gyazo.com/ab7d0180a5019f3dce73d8847244610d/thumb/1000)
- これまたよく見ないでpdb.set_traceつけたままコミットしてんじゃないの
    - そうでもなさそうだなぁ
    - ログ見ないとわからんね
- 次の乗り換えでホームからテザリングして作業するか
    - そんな場所があるかは知らない
- 走ってたアクションを止めた
- スケジュールを変えたつもりでまたpushし忘れたな…
    - リリースしたよという通知メールが来た


デバッグ、謎は解けた
- 埋め込みAPIの失敗が無限にリトライする
- ではなぜ失敗するのか？
- 「前回のノート」が空文字列になっている
- なぜそんなことに？
- GPT4のAPIが失敗してエラーログが前回のノートとして書かれてしまっているケースで、それがノートとして読まれると困るなと思ってスマホから削除した際に空行が残ったため

ふぅん、どうするべきか
- A: 根本的にはエラーログがノートとして読まれうるのがよくない
- B: マーカーの上に空行だけがあるときに、空行を前回のノートとするのはおかしい、今後もうっかりミスで引き起こしうる
- C: そもそも本当に前回のノートが空であるときに、ベクトル検索をしてしまうのがおかしい
    - 当初の設計ではランダムに埋めていたが、そのユースケースは無視して良いと判断していた
    - 空であってもタイトルは存在するのでそれを使う
- D: 本当に埋め込みAPIに空文字列が渡されたとき、無限にリトライするのはおかしい
    - そもそも空文字列が渡されるのがおかしいので即座に例外を投げる
B, C, D fixed: [https://github.com/nishio/omni/commit/33ab6c7ad456c5aa96033603a4f06cb7e5a72465](https://github.com/nishio/omni/commit/33ab6c7ad456c5aa96033603a4f06cb7e5a72465)
A fixed: [https://github.com/nishio/omni/commit/03b6ca3e660ced94fdcbb84e975c62bc115e3d4b](https://github.com/nishio/omni/commit/03b6ca3e660ced94fdcbb84e975c62bc115e3d4b)

帰りの電車でインタラクションするという当初の予定は不発に終わった
- とりあえず全部に目を通してみた
    - OFFにしたもの
        - [[🤖ゼロ知識証明]]
        - [[🤖Signature-based Revocation]]
- まだ微妙だなと思ったものもしばらく実行すると面白いものになるかもしれない
- 今、ベクトル検索多めでやっているので取り尽くすとにていないものを取り始める

[[日記2023-08-22]]←日記2023-08-23→[[日記2023-08-24]]
100日前 [[日記2023-05-15]]
1年前 [[日記2022-08-23]]