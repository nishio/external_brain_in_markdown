---
title: "Hatena2008-12-23"
---

hatena

```
<body>
*1229985164*忘年会から朝帰りしたCUDA日記2
昨日書いていた「2の累乗でない要素数Nの配列のparallel reduction」について。ちなみにやりたい内容はリストの合計を取るだけなので素朴な方法として「2の累乗に足りない部分を0で埋める」が考えられる。あとif文で分岐する方法と、素因数分解して約数でreductionする方法も考えられる。Nが2とか3しか素因数に持たない場合は3番目の方法でいいと思うが、7とかある場合にどうするのが一番早いのか。

を考えたいけどやっぱり眠いので少し寝る。カフェインを摂取したので30～60分後にタイマーをセットすればちょうど血中カフェイン濃度が最高になっているはずだ。

-----

CUDAのコードがどういうインストラクションの列になって、どういう風に処理されていくか見れるといいんだけどな。

ドキュメントを読んだ感じ、下のコードでAとBが全く別の処理だとCPUなら1秒で済むけどGPUだと2秒かかるのだと思っている。試そう。
>||
if(x & 1){ // 奇数のとき
  // 1秒かかる処理A
}else{
  // 1秒かかる処理B
}
||<

-----

確認のためのコードを書いた。スレッドは64個。ブロックが1個。差分は1行なのでdiffスタイルで書いた。

>|cpp|
const int LOOP_SIZE = 1000000;
__global__ static void kernel(const int* input, int* output, clock_t * timer) {
    const int x = threadIdx.x;
    const int bid = blockIdx.x;
    if (x == 0) timer[bid] = clock();

    int v = 0;

-    if(x & 1){
+    if(x < 32){
      for(int i=0; i < LOOP_SIZE; i++){
        v += i;
      }
    }else{
      for(int i=LOOP_SIZE; i > 0; i--){
        v -= i;
      }
    }
    output[x] = v;
    __syncthreads();
    if (x == 0) timer[bid+gridDim.x] = clock();
}
||<

>||
(x & 1)の結果
time = 148000468
time = 148000468
time = 148000468

(x < 32)の結果
time = 86000420
time = 86000404
time = 86000420
||<

倍近い性能差がでるという予想はあっていたけど、148と86がきれいに2倍になっていない理由がよくわからない。なぜだろう。

*1230022340*CUDA日記(Bank Conflictの実験)
計測したい処理を1メガ回繰り返し計算しているので消費クロック数が86000420みたいになる。だから端数は気にせずに86Mと表記することにした。

Bank Conflictが起きるのを確認したくてこういうコードにした。スレッド数は4。
v += i;を繰り返しているあたりのコードから、for文自体のコストは60Mだとわかるので、v += smem[x * 2];のコストが16M、smem[x] += smem[0];のコストが36Mと倍以上であることがわかる。

>|cpp|
const int LOOP_SIZE = 1000000;
__global__ static void kernel(const int* input, int* output, clock_t * timer) {
    const int x = threadIdx.x;
    const int bid = blockIdx.x;
    __shared__ int smem[16];

    if (x == 0) timer[bid] = clock();
    int v = 0;
    for(int i=0; i < LOOP_SIZE; i++){
      //smem[x] += smem[0]; // 96M
      smem[x * 2] += smem[0]; // 80M
      //smem[x] += smem[x + 4]; // 88M
      //smem[x * 2] += smem[x * 2 + 1]; // 80M 
      //v += smem[x * 2]; // 76M
      //v += smem[x]; // 80M
      //v += i; // 80M
      //v += i; v += i; // 100M
      //v += i; v += i; v += i;// 120M
      //v += i + smem[x * 2]; // 80M
    }
    output[x] = v; //smem[x];
    __syncthreads();
    if (x == 0) timer[bid+gridDim.x] = clock();
}
||<

sharedメモリーがBankConflictさえ起こさなければレジスタ並みに速いって書いてあったけど、たしかにスレッドが4つしかない以上iはレジスタに載っているはず。そのiをお足すのより速いとか...あ、違うか。これsmem[x * 2]がループの間ずっと定数だからコンパイラが賢くループの外で取得して定数を足すコードに書き換えているのか。for文の中身を空にしたらfor文ごと削除してくれたりするし、定数に置き換えるくらいのことはやってそうだ。
>||
      //v += smem[x * 2]; // 76M
      //v += smem[x]; // 80M
      //v += i; // 80M
||<

メモリアクセスの方法を変えて節約できるコストはv += i;の5分の1程度だから、reductionや配列を単純にn倍するような「計算の密度がめちゃくちゃ低い処理」でもない限り気にしないでいいんじゃないかと思った。

*1230031948*vim日記(デレ期)
vimのよさがわかってきた。自由にカスタマイズできる環境だとemacsと比較して「なんかややこしいなぁ。emacsだったら普通の言語は最初から全部自動判別して適切なインデントにしてくれるのに」とか思ってしまうけど、今はKnoppixなのでカスタマイズするのがめんどくさいという理由でvimを使っている。.vimrcをいじっていない。

行末に書き加えたいときに行末まで移動しなくてもAでいいのが楽。セミコロンの直前に入れるともっといいんだけど$biかな。
サーチでの移動もまだ使いこなせてないけど便利。/1<Enter>で次の1まで移動。なんかEnterのいらないのもあったはずだけど忘れた。移動してr2とかやって2に書き換えられるのが楽。48を72に書き換えるとかならcwで単語を消して挿入モードに入るのが便利。
emacsでも矩形選択はあったはずだけど覚えてない。vimはvで選択、Vで行選択、<CTRL-v>で矩形選択なので覚えやすい。
オートインデントの機能がデフォルトだと貧弱なので4i<SPACE><ESC>とやって4つスペースを入れたりしているけどもっといい方法があるんだろうか。

*1230032780*プリプロセッサでのelse if
Cっぽく#else ifかと思ったら#elifだった。Pythonと同じ。もちろんPythonの方が後なのだけど、最初にelifを使ったのはCなんだろうか。それとももっと前にelifを使う言語があってそれを真似たんだろうか。

*1230033942*CUDA日記(2の累乗でない配列のparallel reduction実験)
要素数が72個の配列の合計を取る計算は128まで0で埋めてしまった上で普通の2つずつのreductionをする方が速いのか、それとも素因数分解して一部3とかでreductionした方が速いのか、という話。結論から言うと最初に3で割るのが128まで埋めるタイプより1割程度速かった。

42個の場合も試してみたが580が551に減るだけの5%程度の高速化にしかならなかった。42の場合、素因数に7が入っているから微妙なんだな。

いま見直していて気づいたんだけども、zeroで埋めるのを128までではなくて、いっそ72 * 2の144個使うことにすれば__syncthreads()がいらなくなるな。あとsmem[x] = x;のあとに__suncthreads()が必要だな。


>|cpp|
#define N 72
#define NUM_BLOCKS 1
#define CEIL 128
#define TYPE 0

const int LOOP_SIZE = 1000000;
__global__ static void kernel(const int* input, int* output, clock_t * timer) {
    const int x = threadIdx.x;
    const int bid = blockIdx.x;
    __shared__ int smem[CEIL];

    if (x == 0) timer[bid] = clock();
    for(int i=0; i < LOOP_SIZE; i++){
#if TYPE == 0
      // 684M
      // zero reset
      smem[CEIL - N + x] = 0;
      __syncthreads();

      // target values
      smem[x] = x;

      // reduction
      if(x < 64){
      	smem[x] += smem[x + 64];
      }
      __syncthreads();
      if(x < 32){
        smem[x] += smem[x + 32];
        smem[x] += smem[x + 16];
        smem[x] += smem[x + 8];
        smem[x] += smem[x + 4];
        smem[x] += smem[x + 2];
        smem[x] += smem[x + 1];
      }
#elif TYPE == 1
      // 632M
      // target values
      smem[x] = x;

      // reduction
      if(x < 36){
        smem[x] += smem[x + 36];
      }
      __syncthreads();
      if(x < 18){
        smem[x] += smem[x + 18];
	smem[x] += smem[x + 9];
	smem[x] += smem[x + 3] + smem[x + 6];
	smem[x] += smem[x + 1] + smem[x + 2];
      }
#else
      // 624M
      // target values
      smem[x] = x;

      // reduction
      if(x < 24){
        smem[x] += smem[x + 24] + smem[x + 48];
      }
      __syncthreads();
      if(x < 8){
        smem[x] += smem[x + 8] + smem[x + 16];
	smem[x] += smem[x + 4];
	smem[x] += smem[x + 2];
	smem[x] += smem[x + 1];
      }
#endif
      if(x == 0) output[0] = smem[0];
    }
    __syncthreads();
    if (x == 0) timer[bid+gridDim.x] = clock();
}
||<

*1230039090*やりたいことがいっぱいありすぎる
ここ数日脳がハイテンションな状態になって、解決策(かもしれないもの)がぞろぞろ沸いてくるので困る。27か8には実家に帰るつもりでいるので出来ることには限りがある。

C++版の最中限アルゴリズムだけど、カード配列がソートされていれば大小比較を節約できるよね。o1 < o2が既知ならcalc_medianはif文2つでいいようになる。分岐予測もあたりやすくなるかもしれない？

カード配列を、順序を保ったままで削除と復元ができる構造で表現すれば今のコピーがいらないメリットはそのままでさらに高速化できるかもしれない。そういうデータ構造があるか、っていうとあるんだなこれが。追加が起きないことが既知なのだからリンクリストを配列で作ればいい。

これはMacBookがあればできるから実家に帰っている間にやろう。

次にOpenCVとUSBカメラでトランプの画像認識。これはカメラを持ち歩くのは面倒だけどカメラから取った画像をローカルに保存してしまえばThinkpadを実家にもって帰ればすむ。

そしてCUDA。これは現状僕の部屋が外からreachableじゃないので部屋でやるしかない。エミュレータでならMacBookでも開発が出来るけどやっぱ萌えないと思うので。

やっぱCUDAが最優先だなー。

*1230042229*Goolang
Erlangが生まれた頃はGPUPUがなかったので、いっそ今からGoogleがErlang風のVMを新しく作ってしまえばいいんだ。ハードウェアも作ってしまえばいいんだ。言語も作ってしまえばいいんだ。そしてGoolangと名付けるといいんだ！

*1230047914*vim-rogue
ダンジョンを進んでいくとモンスターが現れて、モンスターは書き換え前の文字列と書き換え後の文字列を提示して、書き換え終わるとモンスターを倒せる。時間に応じてヒットポイントが減っていくので素早く書き換えることが重要。

町の魔法屋で魔法書を買うことが出来て、それを読むとvimのコマンドが書いてあるのだが、もちろん使わないと忘れる(文字通りの意味で)

いろいろなステータス異常があって、例えば盲目のステータス異常だとタイプ中の文字列が見えない。敬虔のステータス異常はカーソルキーが使えなくなって初心者泣かせだが、移動時の時間消費が下がるという効果があるので上級者は「敬虔の指輪」を身につけることで故意にステータス異常を起こす。

荷物が重くなればなるほどキーリピートも遅くなる。ゲーム内時間の消費も多くなる。ゲーム内時間は基本的に打鍵数に比例してかかる。ただしメタキーには追加コストがかかる。マップの移動にはvimコマンドが使える。

っていう感じのゲームを誰か作ってくれないかなー

*1230057212*CUDA日記3
シェアードメモリはL1キャッシュに相当するらしい。グローバルメモリはキャッシュされないので必要があれば自分で明示的にキャッシュする。グローバルメモリから読めと指示するのは4クロックで済むが、実際にデータが送られてくるまでに400～600クロックのレイテンシがある。その間十分な個数の独立な処理があればそっちをやれるのでレイテンシを隠すことが出来る。

今日の1つ目のエントリーで書いた、CPUと違って分岐をすると両方の時間がかかるという話、cuda programming guideにちゃんと書いてあった。

clock関数が返してくる値の単位って「the value of a per-multiprocessor counter that is incremented every clock cycle」なんだな。で、コアクロック600MHz、シェーダクロック1500MHzのいったいどっちのクロックなんだろう？シェーダクロックという理解で正しいんだろうか。

だとすると最中限の最終ターンの読み切りは12000クロック程度なので最終ラウンド全体だと1.3秒か。今14個あるブロックのうちの1個しか使っていないのでうまく並列化すれば単純に14倍速くなって0.09秒と。C++のコードの6倍速くなることになるのかな。まぁ、他の計算処理の速くなり具合を見る感じだとそれくらいが妥当なんだろうか。やっぱり一桁速くなってほしかったなぁ。頑張れば一桁速くなるかなぁ。

>||
>>> 12000 * 4 * 9 * 8 * 5 * 11 * 10 / 1500000000.0
1.2672000000000001
>>> _ / 14
0.090514285714285728
||<
</body>
<comments>
<comment>
<username>hoge</username>
<body>選択ならvipもありまっせ。</body>
<timestamp>1230032720</timestamp>
</comment>
<comment>
<username>earth2001y</username>
<body>sh は elif だね</body>
<timestamp>1230038224</timestamp>
</comment>
<comment>
<username>Dubhead</username>
<body>> オートインデントの機能<br>よく分かりませんが、もしかして入力モード中の CTRL-T / CTRL-D のこと言ってます?<br>:he i_CTRL-T 参照。</body>
<timestamp>1230091570</timestamp>
</comment>
</comments>
```


[はてなダイアリー 2008-12-23](https://nishiohirokazu.hatenadiary.org/archive/2008/12/23)