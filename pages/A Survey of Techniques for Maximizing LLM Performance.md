---
title: "A Survey of Techniques for Maximizing LLM Performance"
---

[[OpenAI DevDay]]
![image](https://gyazo.com/7d3bf7ea4b4e83d411ea89961a1a5d1a/thumb/1000)
SNSで見かけたこのグラフ、詳細が気になってたので動画で公開されて嬉しい

45%→65%
- ベースラインは45%だった
- まず[[HyDE]]を試した、これは今回のユースケースでは機能しなかった
- 埋め込みをファインチューニングすることも試した
    - これはアキュラシーの観点ではうまく機能したが、高コストで遅かったため採用できなかった
- チャンクのサイズや区切り方を工夫
    - それによって20%改善して65%になった
    - まだ顧客に渡せるレベルではない
    - ここまでに20イテレーションしている

65%→85%
- [[クロスエンコーダー]]を使ったり、ルールベースのアプローチをしたりして[[リランキング]]
    - ルールの例: 最新のものを使う
    - 大きな性能向上
- 分類
    - ドメインを分類して、それによって異なるメタデータを付与した
    - 具体的には説明されてないが例えばサイボウズ的な文脈で言えば「これはスケジュールだな、参加者の情報を付与しよう」「これはスペースの会話だな、スレッドタイトルとスペースの名前を付与しよう」みたいなことだろう

85%→98%
- 再びプロンプトエンジニアリング
- どのような質問で失敗しているのかを改めて観察
    - 例えば明確な数値を必要とする質問に関して、ドキュメントから抽出するのをやめて、SQLを発行するツールを提供した
- クエリ拡張
    - 名前でイメージした作業と違った(検索対象の側にヒットしやすいデータを付与するのかと思った)
    - ユーザの入力を複数のクエリに分割して、それをパラレルで検索して、合成して返す
    - これはかなりユースケース依存の話だと思う
- どこでもファインチューニングをしてない、これを強調したかった


![image](https://gyazo.com/f83febf41f779bc0456dd7f17fe79bda/thumb/1000)
- ![image](https://gyazo.com/e52fe01c9bd451720c21ee19782207b1/thumb/1000)

[https://www.youtube.com/watch?v=ahnGLM-RC1Y](https://www.youtube.com/watch?v=ahnGLM-RC1Y)

