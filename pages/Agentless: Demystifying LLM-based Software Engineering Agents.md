---
title: "Agentless: Demystifying LLM-based Software Engineering Agents"
---

[https://arxiv.org/abs/2407.01489](https://arxiv.org/abs/2407.01489)
<img src='https://scrapbox.io/api/pages/nishio/o1 Pro/icon' alt='o1 Pro.icon' height="19.5"/>
本研究では、大規模言語モデル（LLM）の[[自律的エージェント]]（[[agent-based]]）アプローチによるソフトウェア開発タスクの自動化が進んでいる一方で、複雑なツール操作や計画立案をLLMに任せることに起因する問題（ツールデザインの煩雑化、意図しない無駄な処理、自己評価力の不足など）が生じているという背景を挙げ、これに対するシンプルな解決策として[[AGENTLESS]]を提案している。

AGENTLESSは、LLMエージェントが「どのツールをいつ使うか」「どのように行動を計画するか」などを自律的に判断するような複雑な仕組みを排し、
- ローカリゼーション（fault localization）
- 修正候補の生成（repair）
- パッチ検証（patch validation）
という3段階の明確なステップに分けて進めるだけのシンプルな枠組みを取っている。この際、LLMには「どのファイルを修正すべきか」「どのクラスや関数のどの行が怪しいか」などを段階的に尋ね、修正候補のパッチはシンプルな差分（Search/Replace 形式）で生成し、最後にテストを使って正しく修正されたかどうかを確認する。LLMにツールや外部環境を操作させることはせず、修正パッチの候補をフィルタリングする役割だけを担わせている点が特徴である。

SWE-bench Lite（GitHub上の実際のイシューと対応するPythonコードを収録したベンチマーク）での評価では、
- AGENTLESSは**32.00%**のイシューを正しく解決し、既存のオープンソースのエージェント手法を上回る性能を示した。
- 1件あたりの推論コストも0.70ドルと低コストで抑えられている。

さらに論文では、SWE-bench Liteのイシューを詳細に分類した結果、
- イシューの説明文自体が不十分・誤解を招く内容であったり、
- 解答となるパッチそのものがイシュー本文に含まれていたり、
といった問題があることを指摘。こうした問題のあるイシューを除外したより厳密なベンチマークSWE-bench Lite-Sを新たに構築し、ここでもAGENTLESSが同様に有効であることを示している。また、OpenAI側でもAGENTLESSをベースに独自のフィルタリングデータセット（SWE-bench Verified）を作成している。

総じて、本研究は、ソフトウェア開発タスクにおけるLLM活用において複雑なエージェント的手法に必ずしも頼らず、段階的かつシンプルな手法（AGENTLESS）でも十分に高い効果と低コストを両立できることを示唆するものであり、従来のエージェントアプローチに対する新たなベースラインや出発点となることを期待している。
