---
title: "Can LLMs Design Good Questions Based on Context?"
---

[https://arxiv.org/abs/2501.03491](https://arxiv.org/abs/2501.03491)

[https://x.com/omarsar0/status/1877008618207560049](https://x.com/omarsar0/status/1877008618207560049)
>  There is a strong preference for asking about specific facts and figures in both LLaMA and GPT models.
>  LLaMAモデルとGPTモデルの両方で、特定の事実や数字について尋ねることが強く求められます。
>  The question lengths tend to be around 20 words but different LLMs tend to exhibit distinct preferences for length.
>  質問の長さは約 20 語である傾向がありますが、異なる <コード id=g1001>LLM は長さに対して明確な好みを示す傾向があります。
>  LLM-generated questions typically require significantly longer answers.
>  LLMで生成された質問は、通常、かなり長い回答を必要とします。
>  Human-generated questions tend to concentrate on the beginning of the context while LLM-generated questions exhibit a more balanced distribution, with a slight decrease in focus at both ends.
>  人間が生成した質問はコンテキストの先頭に集中する傾向がありますが、LLM が生成した質問はよりバランスの取れた分布を示し、両端で焦点がわずかに減少します。

LLMが生成する質問はどこに対して質問するかが満遍ない
