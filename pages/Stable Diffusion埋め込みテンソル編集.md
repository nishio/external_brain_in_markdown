---
title: "Stable Diffusion埋め込みテンソル編集"
---

![image](https://gyazo.com/d2fccb42c4aed55486e8f02e613aaec0/thumb/1000)
- この中央一番上にあるのが"cat"と入れた時に生成される画像
    - 中央一番下が"kitten"(子猫)と入れた時に生成される画像
- これを「単語」と捉えるなら飛び飛びの値だが、実際には768次元のベクトルに対応している
    - となるとそのベクトルを混ぜ合わせることもできる

[https://scrapbox.io/files/63365812630afe001deea2b0.mov](https://scrapbox.io/files/63365812630afe001deea2b0.mov)
- cat kitten間を400分割して毎秒20フレームで動画にしたもの
- 最初4秒くらいどこが変わったのかわかりにくい期間があり、それから急にバタバタと画面が切り替わる
- 滑らかに変化するところ、激しく変化するところがある、これはプロンプトの空間から画像の空間への写像がそれほど滑らかではないということ
    - あまりこれを使って制御は効かない、こう変えたらこうなるかな？といじったものがガサガサしている暴風雨の領域に入ったら予想できない動きになる

- catにtabby(虎猫)を足して いくと柄が濃くなっていって、引いていくと白猫になった
    - ![image](https://gyazo.com/3d5701e780e44d9294af65226e00e117/thumb/1000)
    - こういう納得感のある解釈のできる領域もある
    - 一方でkittenからtabbyを引いたら化け物になったぞ？という予測不可能な現象も起きる
        - ![image](https://gyazo.com/53bad72c88c5d308ae9c5e56dd0f5586/thumb/1000)
    - 穏やかな海の上ではヨットが制御できるが、暴風雨が来るとメチャクチャになる、というイメージ

--- log
> [@nishio](https://twitter.com/nishio/status/1570329982844698625?s=20&t=gkBdZ3SIHmjj7Wer9WDyOA): Stable Diffusionでプロンプトを文字列で人間が書くのではなく埋め込み先のベクトルを直接編集する。文字列に比べて表現力が跳ね上がる。「ちょっと虎猫よりで半分子猫な猫」みたいな指定ができるから。
> ![image](https://pbs.twimg.com/media/FcruvumacAE1QHu.jpg)
- 「ベクトル」と書いたのは書き間違いで、実際は[[Stable Diffusionのpromptは77×768次元のテンソルになる]]
    - word2vec的な理解で「ベクトルになる」と思っている記事がある、僕もそれを見て勘違いしていたがきちんと確認すれば違うということがわかる
    - この例のような「プロンプトが一単語」の場合はテンソルをベクトルだと思い込んで処理しても結果が同じになる
- > [@nishio](https://twitter.com/nishio/status/1570331819740123136): 中央最上段が普通の「cat」、最下段が「kitten」で、右端が+3/7 tabby。tabbyをマイナスすると柄が消えていく。左半分は既存の単語で覆われてない領域なのでデータが少なく、一番編集量の大きい左下には異形が生まれている。

> [@nishio](https://twitter.com/nishio/status/1570336104678838274): "a drawing of *"
> ![image](https://pbs.twimg.com/media/Fcr0SvZaMAEkVE_.jpg)
- 文中の特定の単語だけを編集することもできる
- こういう複数単語からなるプロンプトに「ベクトルとみなした処理」をした場合は、先頭の「a」のベクトルが編集されるのでイマイチ
- 上記の例ではBOSトークンを含んで0オリジンで4番目のベクトルだけを編集している
    - この実験では手でindexを指定してるけど、[[CLIP]]のトークナイザを使って人間にわかりやすくトークンを指定して編集することもできる

余談 [[Stable DiffusionのNSFWフィルタの挙動]]

2022-09-29
> [@nishio](https://twitter.com/nishio/status/1575474901779357703): Stable Diffusionのテンソル編集でcatとkittenの間を百分割し20FPSで5秒の動画にまとめました。フレームの間をクロスフェードで繋いだりしてないのでどういう出力が出るのか直接観察できます。
>  [https://scrapbox.io/files/633591af63315f001d639b71.mov](https://scrapbox.io/files/633591af63315f001d639b71.mov)

> 分解精度をさらに4倍にした(cat〜kitten間を400分割)
>  Twitter上で問題なく見られるかはわからない。
>  [https://scrapbox.io/files/63365812630afe001deea2b0.mov](https://scrapbox.io/files/63365812630afe001deea2b0.mov)
> 最初4秒くらいどこが変わったのかわかりにくい期間があり、それから急にバタバタと画面が切り替わる
>  実は変化していないように見える領域もシークバーでジャンプとかすると変化してることがわかる。つまり変化が人間にとって認識しやすいところで起こっているかの違い。
>  10秒前後のところでヒゲが一本点滅してる。これはヒゲを描くかどうかが境界ギリギリにあるから微妙な値の変化でフリッカーしてる。たまたま点滅したので人間がすぐ気づいたけど、もし滑らかに変わったなら大部分の人は気づかない
>  人間が単語という雑な手段で表現しているベクトルを、400倍細かく制御して滑らかに入力プロンプトを変えているにも関わらず出力の画像が大きく変化する。写像が滑らかではないからだ。ところどころにある穏やかなゾーンでは制御が効きそうに思うが間に暴風雨のゾーンがある。

関連
> [@sugyan](https://twitter.com/sugyan/status/1566801639717056512): stablediffusion でmorphing: Kyoto <-> Tokyo
- ![image](https://gyazo.com/9c0b6c3ed0c5280ef54b29673887643b/thumb/1000)![image](https://gyazo.com/f27e9d79538d7942eb2a66d41c051d8a/thumb/1000)

[Stable Diffusion のプロンプトで意味の足し算・引き算をする](https://zenn.dev/td2sk/articles/eb772103a3a8ff)

