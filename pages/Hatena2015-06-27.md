
hatena

```
<body>
*1435371890*Pyspa日記
Pythonの言語モデルを作り始めた。
サンプル数2038件、サンプルごとの平均トークン数10491、最大トークン数290226。
結構長いトークン列があるから固定のN-gramだともったいない感じがあるなぁ。

トークン種数は135、全21380862トークン。

トークン別の出現数(一部)
>||
NAME 1086490
factor 918992
atom 911487
power 911487
term 897816
arith_expr 885288
shift_expr 884911
and_expr 884475
xor_expr 884412
||<

隠れ層256個でLogLossが10000件終了後に82.29、テストで82.33。その後もゆるゆる走っていて82.35ぐらい。

ミニバッチを1000件
train mean loss=71.2530914678
test  mean loss=71.2531124351

やけにでかいと思ったら2つのトークンで確率がほぼ1になっている。何がいけないのか。
</body>
```


[はてなダイアリー 2015-06-27](https://nishiohirokazu.hatenadiary.org/archive/2015/06/27)